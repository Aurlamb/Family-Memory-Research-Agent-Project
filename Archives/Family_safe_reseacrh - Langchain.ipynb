{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory project - Database vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Load path from the environment variable\n",
    "env_ih1 = os.getenv(\"ENV_IH1\")\n",
    "\n",
    "dotenv_path = Path(env_ih1)\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY= os.getenv('PINECONE_KEY')\n",
    "SERPAPI_API_KEY = os.getenv('SERPAPI_API_KEY')\n",
    "STEAMSHIP_API_KEY = os.getenv('STEAMSHIP_API_KEY')\n",
    "LANGSMITH_API_KEY = os.getenv('LANGSMITH_API_KEY')\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
    "GEMINI_KEY = os.getenv('GEMINI_KEY')\n",
    "\n",
    "os.environ['PATH'] += os.pathsep + '/usr/bin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import shutil\n",
    "from pinecone import Index  # Import Index for Pinecone operations\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Family safe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizer local\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Use your token here\n",
    "login(token=HUGGINGFACEHUB_API_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read json + create local df/csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "OK V1"
    ]
   },
   "outputs": [],
   "source": [
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# def process_json_files(data_dir=r'.\\Family safe', processed_dir=r'.\\Processed JSONs'):\n",
    "#     \"\"\"\n",
    "#     Processes all JSON files in the specified directory and extracts relevant data.\n",
    "\n",
    "#     Args:\n",
    "#         data_dir: Directory containing JSON files.\n",
    "#         processed_dir: Directory where processed files will be moved.\n",
    "\n",
    "#     Returns:\n",
    "#         A DataFrame containing the processed data.\n",
    "#     \"\"\"\n",
    "#     all_data = []\n",
    "\n",
    "#     # Ensure the processed directory exists\n",
    "#     os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "#     # Process each JSON file\n",
    "#     for filename in os.listdir(data_dir):\n",
    "#         if filename.endswith(\".json\"):\n",
    "#             filepath = os.path.join(data_dir, filename)\n",
    "#             with open(filepath, 'r', encoding='utf-8') as f:\n",
    "#                 json_data = json.load(f)\n",
    "\n",
    "#             # Extract document-level metadata\n",
    "#             name = json_data.get(\"Name\", \"Unknown\")\n",
    "#             doc_type = json_data.get(\"Type\", \"Unknown\")\n",
    "#             author = json_data.get(\"Author\", \"Unknown\")\n",
    "#             date = json_data.get(\"Date\", \"Unknown\")\n",
    "\n",
    "#             # Process each page\n",
    "#             for page in json_data.get(\"Pages\", []):\n",
    "#                 page_data = {\n",
    "#                     \"Doc name\": name,\n",
    "#                     \"Type\": doc_type,\n",
    "#                     \"Author\": author,\n",
    "#                     \"Date\": date,\n",
    "#                     \"Text\": page.get(\"Extracted Text\", \"\"),\n",
    "#                     \"Page number\": page.get(\"Page Number\", None),\n",
    "#                 }\n",
    "#                 all_data.append(page_data)\n",
    "\n",
    "#             # Move the processed file\n",
    "#             processed_filepath = os.path.join(processed_dir, filename)\n",
    "#             os.rename(filepath, processed_filepath)\n",
    "\n",
    "#     # Create a DataFrame\n",
    "#     df = pd.DataFrame(all_data)\n",
    "\n",
    "#     # Add summaries to the DataFrame\n",
    "#     df = populate_summary_column(df)\n",
    "\n",
    "#     # Reorder columns\n",
    "#     df = df[[\"Doc name\", \"Type\", \"Author\", \"Date\", \"Text\", \"Page number\", \"Summary\"]]\n",
    "\n",
    "#     return df\n",
    "\n",
    "# def populate_summary_column(df):\n",
    "#     \"\"\"\n",
    "#     Populates the 'Summary' column in the DataFrame using generate_text_summaries.\n",
    "    \n",
    "#     Args:\n",
    "#         df: The DataFrame containing the text data.\n",
    "\n",
    "#     Returns:\n",
    "#         The DataFrame with the 'Summary' column populated.\n",
    "#     \"\"\"\n",
    "#     # Extract texts from the DataFrame\n",
    "#     texts = df[\"Text\"].tolist()\n",
    "\n",
    "#     # Generate summaries for the texts\n",
    "#     text_summaries, _ = generate_text_summaries(texts, tables=None, summarize_texts=True)\n",
    "\n",
    "#     # Assign the summaries back to the DataFrame\n",
    "#     df[\"Summary\"] = text_summaries\n",
    "\n",
    "#     return df\n",
    "\n",
    "# def generate_text_summaries(texts, tables=None, summarize_texts=False):\n",
    "#     \"\"\"\n",
    "#     Summarize text elements\n",
    "#     texts: List of str\n",
    "#     tables: List of str\n",
    "#     summarize_texts: Bool to summarize texts\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Prompt\n",
    "#     prompt_text = \"\"\"You are an assistant tasked with summarizing tables and text for retrieval. \\\n",
    "#     These summaries will be embedded and used to retrieve the raw text or table elements. \\\n",
    "#     Give a concise summary of the table or text that is well optimized for retrieval. Table or text: {element} \n",
    "#     Do not include \"this is a summary\" at the begining of the summary. \"\"\"\n",
    "#     prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "\n",
    "#     # Text summary chain\n",
    "#     model = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "#     summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()\n",
    "\n",
    "#     # Initialize empty summaries\n",
    "#     text_summaries = []\n",
    "#     table_summaries = []\n",
    "\n",
    "#     # Apply to text if texts are provided and summarization is requested\n",
    "#     if texts and summarize_texts:\n",
    "#         text_summaries = summarize_chain.batch(texts, {\"max_concurrency\": 5})\n",
    "#     elif texts:\n",
    "#         text_summaries = texts\n",
    "\n",
    "#     # Apply to tables if tables are provided\n",
    "#     if tables:\n",
    "#         table_summaries = summarize_chain.batch(tables, {\"max_concurrency\": 5})\n",
    "\n",
    "#     return text_summaries, table_summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V2\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def process_json_files(data_dir=r'.\\Family safe', processed_dir=r'.\\Processed JSONs', output_file=r'.\\combined_data.csv'):\n",
    "    \"\"\"\n",
    "    Processes all JSON files in the specified directory, adds new data to an existing DataFrame, \n",
    "    and ensures no duplicates.\n",
    "\n",
    "    Args:\n",
    "        data_dir: Directory containing JSON files.\n",
    "        processed_dir: Directory where processed files will be moved.\n",
    "        output_file: Filepath for the saved combined DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame containing the updated processed data.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "\n",
    "    # Ensure the processed directory exists\n",
    "    os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "    # Process each JSON file\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.endswith(\".json\"):\n",
    "            filepath = os.path.join(data_dir, filename)\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                json_data = json.load(f)\n",
    "\n",
    "            # Extract document-level metadata\n",
    "            name = json_data.get(\"Name\", \"Unknown\")\n",
    "            doc_type = json_data.get(\"Type\", \"Unknown\")\n",
    "            author = json_data.get(\"Author\", \"Unknown\")\n",
    "            date = json_data.get(\"Date\", \"Unknown\")\n",
    "\n",
    "            # Initialize a page counter\n",
    "            page_counter = 1\n",
    "\n",
    "            # Process each page\n",
    "            for page in json_data.get(\"Pages\", []):\n",
    "                page_number = page.get(\"Page Number\", None)\n",
    "                \n",
    "                # Assign a sequential number if Page Number is NaN\n",
    "                if page_number is None:\n",
    "                    page_number = page_counter\n",
    "                    page_counter += 1  # Increment the counter\n",
    "\n",
    "                page_data = {\n",
    "                    \"Doc name\": name,\n",
    "                    \"Type\": doc_type,\n",
    "                    \"Author\": author,\n",
    "                    \"Date\": date,\n",
    "                    \"Text\": page.get(\"Extracted Text\", \"\"),\n",
    "                    \"Chunks\": page_number,\n",
    "                }\n",
    "                all_data.append(page_data)\n",
    "\n",
    "\n",
    "            # Move the processed file\n",
    "            processed_filepath = os.path.join(processed_dir, filename)\n",
    "            os.rename(filepath, processed_filepath)\n",
    "\n",
    "    # Create a DataFrame from new data\n",
    "    new_df = pd.DataFrame(all_data)\n",
    "\n",
    "    # Add summaries to the new DataFrame\n",
    "    new_df = populate_summary_column(new_df)\n",
    "\n",
    "    # Reorder columns\n",
    "    new_df = new_df[[\"Doc name\", \"Type\", \"Author\", \"Date\", \"Text\", \"Chunks\", \"Summary\"]]\n",
    "\n",
    "    # Check if an existing DataFrame exists\n",
    "    if os.path.exists(output_file):\n",
    "        existing_df = pd.read_csv(output_file)\n",
    "        combined_df = pd.concat([existing_df, new_df], ignore_index=True).drop_duplicates()\n",
    "    else:\n",
    "        combined_df = new_df\n",
    "\n",
    "    # Save the updated DataFrame\n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "    print(f\"Updated DataFrame saved to {output_file}\")\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "def populate_summary_column(df):\n",
    "    \"\"\"\n",
    "    Populates the 'Summary' column in the DataFrame using generate_text_summaries.\n",
    "    \n",
    "    Args:\n",
    "        df: The DataFrame containing the text data.\n",
    "\n",
    "    Returns:\n",
    "        The DataFrame with the 'Summary' column populated.\n",
    "    \"\"\"\n",
    "    # Extract texts from the DataFrame\n",
    "    texts = df[\"Text\"].tolist()\n",
    "\n",
    "    # Generate summaries for the texts\n",
    "    text_summaries, _ = generate_text_summaries(texts, tables=None, summarize_texts=True)\n",
    "\n",
    "    # Assign the summaries back to the DataFrame\n",
    "    df[\"Summary\"] = text_summaries\n",
    "\n",
    "    return df\n",
    "\n",
    "def generate_text_summaries(texts, tables=None, summarize_texts=False):\n",
    "    \"\"\"\n",
    "    Summarize text elements\n",
    "    texts: List of str\n",
    "    tables: List of str\n",
    "    summarize_texts: Bool to summarize texts\n",
    "    \"\"\"\n",
    "\n",
    "    # Prompt\n",
    "    prompt_text = \"\"\"You are an assistant tasked with summarizing tables and text for retrieval. \\\n",
    "    These summaries will be embedded and used to retrieve the raw text or table elements. \\\n",
    "    Give a concise summary of the table or text that is well optimized for retrieval. Table or text: {element} \n",
    "    Do not include \"this is a summary\" at the begining of the summary. \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "\n",
    "    # Text summary chain\n",
    "    model = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "    summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()\n",
    "\n",
    "    # Initialize empty summaries\n",
    "    text_summaries = []\n",
    "    table_summaries = []\n",
    "\n",
    "    # Apply to text if texts are provided and summarization is requested\n",
    "    if texts and summarize_texts:\n",
    "        text_summaries = summarize_chain.batch(texts, {\"max_concurrency\": 5})\n",
    "    elif texts:\n",
    "        text_summaries = texts\n",
    "\n",
    "    # Apply to tables if tables are provided\n",
    "    if tables:\n",
    "        table_summaries = summarize_chain.batch(tables, {\"max_concurrency\": 5})\n",
    "\n",
    "    return text_summaries, table_summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame saved to .\\combined_data.csv\n"
     ]
    }
   ],
   "source": [
    "df=process_json_files(data_dir=r'data\\Family safe', processed_dir=r'data\\Family safe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run the function\n",
    "# updated_df = process_json_files(data_dir=r'.\\Family safe', processed_dir=r'.\\Family safe')\n",
    "\n",
    "# # Preview the updated DataFrame\n",
    "# print(updated_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m50\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Doc name  Type          Author                 Date  \\\n",
      "0                example_name  scan  example_author  2025-01-23 17:17:14   \n",
      "1                example_name  scan  example_author  2025-01-23 17:17:14   \n",
      "2                example_name  scan  example_author  2025-01-23 17:17:14   \n",
      "3                example_name  scan  example_author  2025-01-23 17:17:14   \n",
      "4                example_name  scan  example_author  2025-01-23 17:17:14   \n",
      "..                        ...   ...             ...                  ...   \n",
      "134              example_name  scan  example_author  2025-01-23 17:17:14   \n",
      "137              example_name  scan  example_author  2025-01-23 17:17:14   \n",
      "142  La belle au bois dormant  scan        Perrault  2025-01-24 12:16:38   \n",
      "143  La belle au bois dormant  scan        Perrault  2025-01-24 12:16:38   \n",
      "144  La belle au bois dormant  scan        Perrault  2025-01-24 12:16:38   \n",
      "\n",
      "                                                  Text  Chunks  \\\n",
      "0    CC-OCR: A Comprehensive and Challenging OCR Be...       1   \n",
      "1    only includes reading plain texts but also inv...       2   \n",
      "2    ---\\nLMMS\\nStructured inputs and outputs\\nFine...       3   \n",
      "3    TextMonkey\\nKOSMOS2.5-20.9\\nTotal\\nMulti-Scene...       4   \n",
      "4    Table 1. Comparisons of different benchmarks f...       1   \n",
      "..                                                 ...     ...   \n",
      "134  1 cashew nuts chkn\\n64,500\\n1 garlic pepper be...      11   \n",
      "137  69844E\\n7101\\n806 41\\n009620\\n0096\\n0969\\n0096...      14   \n",
      "142  LA BELLE AU BOIS DORMANT\\n\\nIl était une fois ...       1   \n",
      "143  LA BELLE AU BOIS DORMANT\\n\\nLa plus jeune lui ...       2   \n",
      "144  ---\\nLA BELLE AU BOIS DORMANT\\n\\n— Que faites-...       3   \n",
      "\n",
      "                                               Summary  \n",
      "0    CC-OCR is a comprehensive benchmark designed t...  \n",
      "1    The text discusses the development of CC-OCR, ...  \n",
      "2    The content covers various topics including st...  \n",
      "3    The text discusses a comparative analysis of v...  \n",
      "4    Table 1 compares various benchmarks for evalua...  \n",
      "..                                                 ...  \n",
      "134  Order Summary:  \\n- Cashew Nuts Chicken: 64,50...  \n",
      "137  The text includes a menu and pricing details f...  \n",
      "142  In \"La Belle au Bois Dormant,\" a king and quee...  \n",
      "143  In \"La Belle au Bois Dormant,\" a young princes...  \n",
      "144  In \"La Belle au Bois Dormant,\" a princess pric...  \n",
      "\n",
      "[132 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# del df\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pinecone DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Pinecone DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone as pc\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "spec = ServerlessSpec(\n",
    "    cloud=\"aws\", region=\"us-east-1\"\n",
    ")\n",
    "\n",
    "# connect to pinecone environment\n",
    "pc = Pinecone(\n",
    "    api_key = PINECONE_API_KEY,\n",
    "    environment='us-east-1'  # find next to API key in console\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 3}},\n",
       " 'total_vector_count': 3}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "index_name = \"memory-project\"\n",
    "existing_indexes = [\n",
    "    index_info[\"name\"] for index_info in pc.list_indexes()\n",
    "]\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in existing_indexes:\n",
    "    # if does not exist, create index\n",
    "    pc.create_index(\n",
    "        index_name,\n",
    "        dimension=1536,  # dimensionality of ada 002\n",
    "        metric='dotproduct',\n",
    "        spec=spec\n",
    "    )\n",
    "    # wait for index to be initialized\n",
    "    while not pc.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)\n",
    "\n",
    "# connect to index\n",
    "index = pc.Index(index_name)\n",
    "time.sleep(1)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurel\\AppData\\Local\\Temp\\ipykernel_38612\\2425522339.py:13: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embed = OpenAIEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import torch\n",
    "\n",
    "# get API key from top-right dropdown on OpenAI website\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\") or getpass(\"Enter your OpenAI API key: \")\n",
    "model_name = 'text-embedding-3-small'\n",
    "\n",
    "# set device to GPU if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "embed = OpenAIEmbeddings(\n",
    "    model=model_name,\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    # device=device -> Not compatible with OpenAI embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ece2620746e4ce980f4f0338a1148a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Indexing\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "texts = []\n",
    "metadata = []\n",
    "\n",
    "for i in tqdm(range(0, len(df), batch_size)):\n",
    "    # get end of batch\n",
    "    i_end = min(len(df), i+batch_size)\n",
    "    batch = df.iloc[i:i_end]\n",
    "\n",
    "    # first get metadata fields for this record\n",
    "    metadata = [{\n",
    "        'Doc name': record['Doc name'],\n",
    "        'Author': record['Author'],\n",
    "        'Date': record['Date'],\n",
    "        'Chunks': record['Chunks'],\n",
    "        'Summary': record['Summary'],\n",
    "\n",
    "    } for j, record in batch.iterrows()]\n",
    "    # Extract full text for embeddings\n",
    "    embeddings = embed.embed_documents(batch[\"Text\"].tolist())\n",
    "\n",
    "    # Prepare IDs\n",
    "    ids = batch[\"Doc name\"].tolist()\n",
    "\n",
    "    # Upsert to Pinecone\n",
    "    index.upsert(vectors=zip(ids, embeddings, metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurel\\AppData\\Local\\Temp\\ipykernel_38612\\2222631083.py:6: LangChainDeprecationWarning: The class `Pinecone` was deprecated in LangChain 0.0.18 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-pinecone package and should be used instead. To use it run `pip install -U :class:`~langchain-pinecone` and import as `from :class:`~langchain_pinecone import Pinecone``.\n",
      "  vectorstore = Pinecone(\n",
      "C:\\Users\\aurel\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_community\\vectorstores\\pinecone.py:68: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "text_field = \"Summary\"  # the metadata field that contains our text\n",
    "\n",
    "# initialize the vector store object\n",
    "vectorstore = Pinecone(\n",
    "    index, embed.embed_query, text_field\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Author': 'John Doe', 'Chunks': 118.0, 'Date': '2025-01-23 15:43:26', 'Doc name': 'Pdf img'}, page_content=\"Isaac, souvent appelé Louis, est l'ancêtre direct né en 1766 à Froeningen, marié à Rachel Gugenheim (1772-1843). Ils ont eu six enfants, dont Lehmann (Clément), né en 1800, qui a épousé Athelle Bloch en 1827. Ils ont eu neuf enfants, parmi lesquels Jacques Dreyfus, né le 9 janvier 1829, qui a épousé Catherine Lévy en 1860 et est décédé en 1893. Jacques, colporteur de tissus, a joué un rôle significatif dans la famille, voyageant pour approvisionner des revendeurs dans des bourgs non desservis.\"),\n",
       " Document(metadata={'Author': 'Perrault', 'Chunks': 3.0, 'Date': '2025-01-24 12:16:38', 'Doc name': 'La belle au bois dormant'}, page_content='In \"La Belle au Bois Dormant,\" a princess encounters an old woman spinning. Curious, she tries to spin but pricks her finger on a spindle, falling into a deep sleep as foretold by the fairies. Despite efforts to revive her, she remains unconscious. The king, recalling the fairy\\'s prophecy, places her in a beautifully adorned bed, where she appears angelic, still breathing. He decides to let her sleep until the time of her awakening. Meanwhile, a good fairy, alerted by a swift messenger, learns of the incident from afar.'),\n",
       " Document(metadata={'Author': 'example_author', 'Chunks': 14.0, 'Date': '2025-01-23 17:17:14', 'Doc name': 'example_name'}, page_content='The text includes a menu and pricing details for various food items and promotions at a restaurant. Key offerings include:\\n\\n1. **Gemini-1.5-Pro Menu**:\\n   - Dishes: Cashew nuts chicken, garlic pepper beef, red curry beef, phad thai, steamed rice.\\n   - Subtotal: 325,600; Service charge: 10%; Total: 377,859.\\n\\n2. **Qwen2-VL-72B Menu**:\\n   - Similar dishes with a total of 377,859 and a subtotal of 412,108 after service charge.\\n\\n3. **Promotions**:\\n   - Buy one get one free on selected breads from September 1 to October 5.\\n   - Breakfast sets available: Classic Breakfast A (22元), Classic Breakfast B (33元), and various other breakfast options.\\n\\n4. **New Items**:\\n   - French-style hot dogs paired with coffee options, all priced at 32元.\\n\\n5. **Additional Breakfast Options**:\\n   - Energetic Breakfast A (33元), B (29元), and Light Breakfast (25元).\\n\\nThe text also mentions specific time frames for promotions and the availability of certain breakfast sets.')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Qui est Rachel Gugenheim?\"\n",
    "\n",
    "vectorstore.similarity_search(\n",
    "    query,  # our search query\n",
    "    k=3  # return 3 most relevant docs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'Author': 'John Doe', 'Chunks': 118.0, 'Date': '2025-01-23 15:43:26', 'Doc name': 'Pdf img'}, page_content=\"Isaac, souvent appelé Louis, est l'ancêtre direct né en 1766 à Froeningen, marié à Rachel Gugenheim (1772-1843). Ils ont eu six enfants, dont Lehmann (Clément), né en 1800, qui a épousé Athelle Bloch en 1827. Ils ont eu neuf enfants, parmi lesquels Jacques Dreyfus, né le 9 janvier 1829, qui a épousé Catherine Lévy en 1860 et est décédé en 1893. Jacques, colporteur de tissus, a joué un rôle significatif dans la famille, voyageant pour approvisionner des revendeurs dans des bourgs non desservis.\"), Document(metadata={'Author': 'Perrault', 'Chunks': 3.0, 'Date': '2025-01-24 12:16:38', 'Doc name': 'La belle au bois dormant'}, page_content='In \"La Belle au Bois Dormant,\" a princess encounters an old woman spinning. Curious, she tries to spin but pricks her finger on a spindle, falling into a deep sleep as foretold by the fairies. Despite efforts to revive her, she remains unconscious. The king, recalling the fairy\\'s prophecy, places her in a beautifully adorned bed, where she appears angelic, still breathing. He decides to let her sleep until the time of her awakening. Meanwhile, a good fairy, alerted by a swift messenger, learns of the incident from afar.'), Document(metadata={'Author': 'example_author', 'Chunks': 14.0, 'Date': '2025-01-23 17:17:14', 'Doc name': 'example_name'}, page_content='The text includes a menu and pricing details for various food items and promotions at a restaurant. Key offerings include:\\n\\n1. **Gemini-1.5-Pro Menu**:\\n   - Dishes: Cashew nuts chicken, garlic pepper beef, red curry beef, phad thai, steamed rice.\\n   - Subtotal: 325,600; Service charge: 10%; Total: 377,859.\\n\\n2. **Qwen2-VL-72B Menu**:\\n   - Similar dishes with a total of 377,859 and a subtotal of 412,108 after service charge.\\n\\n3. **Promotions**:\\n   - Buy one get one free on selected breads from September 1 to October 5.\\n   - Breakfast sets available: Classic Breakfast A (22元), Classic Breakfast B (33元), and various other breakfast options.\\n\\n4. **New Items**:\\n   - French-style hot dogs paired with coffee options, all priced at 32元.\\n\\n5. **Additional Breakfast Options**:\\n   - Energetic Breakfast A (33元), B (29元), and Light Breakfast (25元).\\n\\nThe text also mentions specific time frames for promotions and the availability of certain breakfast sets.')]\n"
     ]
    }
   ],
   "source": [
    "print(vectorstore.similarity_search(query, k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurel\\AppData\\Local\\Temp\\ipykernel_38612\\846565193.py:6: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n",
      "C:\\Users\\aurel\\AppData\\Local\\Temp\\ipykernel_38612\\846565193.py:12: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  conversational_memory = ConversationBufferWindowMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# chat completion llm\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model_name='gpt-4o-mini',\n",
    "    temperature=0.0\n",
    ")\n",
    "# conversational memory\n",
    "conversational_memory = ConversationBufferWindowMemory(\n",
    "    memory_key='chat_history',\n",
    "    k=5,\n",
    "    return_messages=True\n",
    ")\n",
    "# retrieval qa chain\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurel\\AppData\\Local\\Temp\\ipykernel_38612\\2828950282.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  qa.run(query)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Rachel Gugenheim est l'épouse d'Isaac, souvent appelé Louis. Elle est née en 1772 et est décédée en 1843. Ils ont eu six enfants ensemble.\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool query to be edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name='Knowledge Base',\n",
    "        func=qa.run,\n",
    "        description=(\n",
    "            'use this tool when answering general knowledge queries to get '\n",
    "            'more information about the topic'\n",
    "        )\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurel\\AppData\\Local\\Temp\\ipykernel_38612\\640423283.py:3: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "agent = initialize_agent(\n",
    "    agent='chat-conversational-react-description',\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    early_stopping_method='generate',\n",
    "    memory=conversational_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurel\\AppData\\Local\\Temp\\ipykernel_38612\\4075506381.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  agent(\"Who si Rachel Gugenheim?\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Knowledge Base\",\n",
      "    \"action_input\": \"Rachel Gugenheim\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mRachel Gugenheim (1772-1843) était l'épouse d'Isaac, souvent appelé Louis, et ils ont eu six enfants ensemble.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Rachel Gugenheim (1772-1843) was the wife of Isaac, often referred to as Louis, and they had six children together.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Who si Rachel Gugenheim?',\n",
       " 'chat_history': [],\n",
       " 'output': 'Rachel Gugenheim (1772-1843) was the wife of Isaac, often referred to as Louis, and they had six children together.'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\"Who si Rachel Gugenheim?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Knowledge Base\",\n",
      "    \"action_input\": \"Isaac Gugenheim, husband of Rachel Gugenheim\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIsaac Gugenheim, souvent appelé Louis, est l'ancêtre direct né en 1766 à Froeningen. Il était marié à Rachel Gugenheim, qui a vécu de 1772 à 1843. Ils ont eu six enfants ensemble.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Isaac Gugenheim, often referred to as Louis, was born in 1766 in Froeningen. He was married to Rachel Gugenheim, who lived from 1772 to 1843, and they had six children together.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What can you tell me about her husband?',\n",
       " 'chat_history': [HumanMessage(content='Who si Rachel Gugenheim?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Rachel Gugenheim (1772-1843) was the wife of Isaac, often referred to as Louis, and they had six children together.', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'Isaac Gugenheim, often referred to as Louis, was born in 1766 in Froeningen. He was married to Rachel Gugenheim, who lived from 1772 to 1843, and they had six children together.'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\"What can you tell me about her husband?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Knowledge Base\",\n",
      "    \"action_input\": \"common point between Jacques Dreyfus and Sleeping Beauty\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe common point between Jacques Dreyfus and Sleeping Beauty is that both involve themes of waiting and transformation. In \"Sleeping Beauty,\" the princess is in a deep sleep for a long period, awaiting a transformative awakening. Similarly, Jacques Dreyfus, as a traveling merchant, may have experienced periods of waiting during his journeys, and his life story reflects a transformation through his role in the family and community. Both narratives highlight the passage of time and the eventual change that comes with it.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"The common point between Jacques Dreyfus and Sleeping Beauty is that both involve themes of waiting and transformation. In 'Sleeping Beauty,' the princess is in a deep sleep for a long period, awaiting a transformative awakening. Similarly, Jacques Dreyfus, as a traveling merchant, may have experienced periods of waiting during his journeys, and his life story reflects a transformation through his role in the family and community. Both narratives highlight the passage of time and the eventual change that comes with it.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What's the common point between Jacques Dreyfus and Sleeping Beauty?\",\n",
       " 'chat_history': [HumanMessage(content='Who si Rachel Gugenheim?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Rachel Gugenheim (1772-1843) was the wife of Isaac, often referred to as Louis, and they had six children together.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What can you tell me about her husband?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Isaac Gugenheim, often referred to as Louis, was born in 1766 in Froeningen. He was married to Rachel Gugenheim, who lived from 1772 to 1843, and they had six children together.', additional_kwargs={}, response_metadata={})],\n",
       " 'output': \"The common point between Jacques Dreyfus and Sleeping Beauty is that both involve themes of waiting and transformation. In 'Sleeping Beauty,' the princess is in a deep sleep for a long period, awaiting a transformative awakening. Similarly, Jacques Dreyfus, as a traveling merchant, may have experienced periods of waiting during his journeys, and his life story reflects a transformation through his role in the family and community. Both narratives highlight the passage of time and the eventual change that comes with it.\"}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\"What's the common point between Jacques Dreyfus and Sleeping Beauty?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Knowledge Base\",\n",
      "    \"action_input\": \"Jacques Dreyfus\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mJacques Dreyfus, né le 9 janvier 1829, était un colporteur de tissus qui a joué un rôle significatif dans sa famille. Il a épousé Catherine Lévy en 1860 et est décédé en 1893. Il était l'un des neuf enfants de Lehmann (Clément) et Athelle Bloch.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Jacques Dreyfus, born on January 9, 1829, was a significant figure as a traveling fabric merchant. He married Catherine Lévy in 1860 and passed away in 1893. He was one of nine children of Lehmann (Clément) and Athelle Bloch.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me all you know about Jacques Dreyfus.',\n",
       " 'chat_history': [HumanMessage(content='Who si Rachel Gugenheim?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Rachel Gugenheim (1772-1843) was the wife of Isaac, often referred to as Louis, and they had six children together.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What can you tell me about her husband?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Isaac Gugenheim, often referred to as Louis, was born in 1766 in Froeningen. He was married to Rachel Gugenheim, who lived from 1772 to 1843, and they had six children together.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"What's the common point between Jacques Dreyfus and Sleeping Beauty?\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"The common point between Jacques Dreyfus and Sleeping Beauty is that both involve themes of waiting and transformation. In 'Sleeping Beauty,' the princess is in a deep sleep for a long period, awaiting a transformative awakening. Similarly, Jacques Dreyfus, as a traveling merchant, may have experienced periods of waiting during his journeys, and his life story reflects a transformation through his role in the family and community. Both narratives highlight the passage of time and the eventual change that comes with it.\", additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'Jacques Dreyfus, born on January 9, 1829, was a significant figure as a traveling fabric merchant. He married Catherine Lévy in 1860 and passed away in 1893. He was one of nine children of Lehmann (Clément) and Athelle Bloch.'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\"Tell me all you know about Jacques Dreyfus.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
