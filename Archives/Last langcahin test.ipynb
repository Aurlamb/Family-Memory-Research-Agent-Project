{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt-get' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme exï¿½cutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "!apt-get install graphviz libgraphviz-dev pkg-config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain langchain-community langchain-groq langchain-core langchain-pinecone gpt4all langgraph sentence-transformers gradio langchain-huggingface groq ollama cohere langchain pinecone-client PyPDF2 einops html2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#': Expected package name at the start of dependency specifier\n",
      "    #\n",
      "    ^\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU \\\n",
    "    datasets==2.19.1 \\\n",
    "    langchain-pinecone==0.1.1 \\\n",
    "    langchain-openai==0.1.9 \\\n",
    "    langchain==0.2.5 \\\n",
    "    langchain-core==0.2.9 \\\n",
    "    langgraph==0.1.1 \\\n",
    "    semantic-router==0.0.48 \\\n",
    "    serpapi==0.1.5 \\\n",
    "    google-search-results==2.4.2 \\\n",
    "    pygraphviz==1.12  # for visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders.web_base import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import nest_asyncio\n",
    "from langchain_community.vectorstores.chroma import Chroma\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import Literal\n",
    "from langchain.chains.combine_documents import stuff\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from IPython.core.display import Markdown\n",
    "import json\n",
    "import re\n",
    "from langchain_core.runnables import (\n",
    "    RunnableParallel,\n",
    "    RunnableBranch,\n",
    "    RunnablePassthrough,\n",
    ")\n",
    "from langchain_core.pydantic_v1 import validator\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from operator import itemgetter\n",
    "import asyncio\n",
    "import warnings\n",
    "import PyPDF2\n",
    "from typing import overload, Optional\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "from langchain.document_transformers import Html2TextTransformer\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.prebuilt import ToolInvocation, ToolExecutor\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_core.messages.base import BaseMessage\n",
    "import operator\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Load path from the environment variable\n",
    "env_ih1 = os.getenv(\"ENV_IH1\")\n",
    "\n",
    "dotenv_path = Path(env_ih1)\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY= os.getenv('PINECONE_KEY')\n",
    "SERPAPI_API_KEY = os.getenv('SERPAPI_API_KEY')\n",
    "STEAMSHIP_API_KEY = os.getenv('STEAMSHIP_API_KEY')\n",
    "LANGSMITH_API_KEY = os.getenv('LANGSMITH_API_KEY')\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
    "GEMINI_KEY = os.getenv('GEMINI_KEY')\n",
    "\n",
    "os.environ['PATH'] += os.pathsep + '/usr/bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Outputs:\n",
      "{'query': 'Who is Dreyfus?', 'embedding_info': [HumanMessage(content='Generated embedding for query: Who is Dreyfus?', additional_kwargs={}, response_metadata={}, id='efef83d2-1ae8-498d-b6c4-eacbcb8e9f85')], 'results': ['Doc 1: Relevant to Who is Dreyfus?', 'Doc 2: Relevant to Who is Dreyfus?', 'Doc 3: Relevant to Who is Dreyfus?']}\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
