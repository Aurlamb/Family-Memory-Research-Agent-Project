{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyvWVMBTDX2M"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pinecone-io/examples/blob/master/learn/generation/langchain/langgraph/01-gpt-4o-research-agent.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/pinecone-io/examples/blob/master/learn/generation/langchain/langgraph/01-gpt-4o-research-agent.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PFp0JhOWCU5"
      },
      "source": [
        "# GPT-4o Research Agent in LangGraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TCVLlfNyAtxD",
        "outputId": "a281097c-e50a-4106-e997-58ff87314ea5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'apt-get' n'est pas reconnu en tant que commande interne\n",
            "ou externe, un programme ex�cutable ou un fichier de commandes.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install graphviz libgraphviz-dev pkg-config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbR8rt-EtqWh"
      },
      "source": [
        "Now we install Python libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "FUt2EoJZu6M3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × Building wheel for pygraphviz (pyproject.toml) did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [51 lines of output]\n",
            "      running bdist_wheel\n",
            "      running build\n",
            "      running build_py\n",
            "      creating build\\lib.win-amd64-cpython-312\\pygraphviz\n",
            "      copying pygraphviz\\agraph.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\n",
            "      copying pygraphviz\\graphviz.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\n",
            "      copying pygraphviz\\scraper.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\n",
            "      copying pygraphviz\\testing.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\n",
            "      copying pygraphviz\\__init__.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\n",
            "      creating build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_attribute_defaults.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_clear.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_close.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_drawing.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_edge_attributes.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_graph.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_html.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_layout.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_node_attributes.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_readwrite.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_repr_mimebundle.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_scraper.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_string.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_subgraph.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_unicode.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\__init__.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      running egg_info\n",
            "      writing pygraphviz.egg-info\\PKG-INFO\n",
            "      writing dependency_links to pygraphviz.egg-info\\dependency_links.txt\n",
            "      writing top-level names to pygraphviz.egg-info\\top_level.txt\n",
            "      reading manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n",
            "      reading manifest template 'MANIFEST.in'\n",
            "      warning: no files found matching '*.png' under directory 'doc'\n",
            "      warning: no files found matching '*.html' under directory 'doc'\n",
            "      warning: no files found matching '*.txt' under directory 'doc'\n",
            "      warning: no files found matching '*.css' under directory 'doc'\n",
            "      warning: no previously-included files matching '*~' found anywhere in distribution\n",
            "      warning: no previously-included files matching '*.pyc' found anywhere in distribution\n",
            "      warning: no previously-included files matching '.svn' found anywhere in distribution\n",
            "      no previously-included directories found matching 'doc\\build'\n",
            "      adding license file 'LICENSE'\n",
            "      writing manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n",
            "      copying pygraphviz\\graphviz.i -> build\\lib.win-amd64-cpython-312\\pygraphviz\n",
            "      copying pygraphviz\\graphviz_wrap.c -> build\\lib.win-amd64-cpython-312\\pygraphviz\n",
            "      running build_ext\n",
            "      building 'pygraphviz._graphviz' extension\n",
            "      creating build\\temp.win-amd64-cpython-312\\Release\\pygraphviz\n",
            "      \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.42.34433\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -DSWIG_PYTHON_STRICT_BYTE_CHAR -DGVDLL -Ic:\\Users\\aurel\\OneDrive\\Documents\\Python\\IronHack\\W8\\D2\\lab-langsmith-summarizations\\.conda\\include -Ic:\\Users\\aurel\\OneDrive\\Documents\\Python\\IronHack\\W8\\D2\\lab-langsmith-summarizations\\.conda\\Include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.42.34433\\include\" \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Auxiliary\\VS\\include\" /Tcpygraphviz/graphviz_wrap.c /Fobuild\\temp.win-amd64-cpython-312\\Release\\pygraphviz\\graphviz_wrap.obj\n",
            "      graphviz_wrap.c\n",
            "      c:\\Users\\aurel\\OneDrive\\Documents\\Python\\IronHack\\W8\\D2\\lab-langsmith-summarizations\\.conda\\include\\pyconfig.h(59): fatal error C1083: Impossible d'ouvrir le fichier includeÿ: 'io.h'ÿ: No such file or directory\n",
            "      error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2022\\\\BuildTools\\\\VC\\\\Tools\\\\MSVC\\\\14.42.34433\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  ERROR: Failed building wheel for pygraphviz\n",
            "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pygraphviz)\n"
          ]
        }
      ],
      "source": [
        "# Installing required Python libraries\n",
        "%pip install -qU \\\n",
        "    langchain-pinecone==0.1.1 \\\n",
        "    langchain-openai==0.1.9 \\\n",
        "    langchain==0.2.5 \\\n",
        "    langchain-core==0.2.9 \\\n",
        "    langgraph \\\n",
        "    semantic-router==0.0.48 \\\n",
        "    serpapi==0.1.5 \\\n",
        "    google-search-results==2.4.2 \\\n",
        "    pygraphviz==1.12\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "20fNb5pyQTmA",
        "outputId": "7af185be-655e-4164-946a-672eec2ecb3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: semantic-router in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (0.0.72)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.5 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from semantic-router) (3.10.11)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from semantic-router) (0.4.6)\n",
            "Requirement already satisfied: colorlog<7.0.0,>=6.8.0 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from semantic-router) (6.9.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.25.2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from semantic-router) (1.26.4)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from semantic-router) (1.60.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.3 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from semantic-router) (2.10.5)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.1 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from semantic-router) (6.0.2)\n",
            "Requirement already satisfied: regex>=2023.12.25 in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from semantic-router) (2024.11.6)\n",
            "Requirement already satisfied: requests-mock<2.0.0,>=1.12.1 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from semantic-router) (1.12.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.6.0 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from semantic-router) (0.8.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.9.5->semantic-router) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.9.5->semantic-router) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.9.5->semantic-router) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.9.5->semantic-router) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.9.5->semantic-router) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.9.5->semantic-router) (1.18.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from openai<2.0.0,>=1.10.0->semantic-router) (4.8.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from openai<2.0.0,>=1.10.0->semantic-router) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from openai<2.0.0,>=1.10.0->semantic-router) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from openai<2.0.0,>=1.10.0->semantic-router) (0.8.2)\n",
            "Requirement already satisfied: sniffio in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from openai<2.0.0,>=1.10.0->semantic-router) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from openai<2.0.0,>=1.10.0->semantic-router) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from openai<2.0.0,>=1.10.0->semantic-router) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from pydantic<3.0.0,>=2.5.3->semantic-router) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3.0.0,>=2.5.3->semantic-router) (2.27.2)\n",
            "Requirement already satisfied: requests<3,>=2.22 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from requests-mock<2.0.0,>=1.12.1->semantic-router) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->semantic-router) (3.10)\n",
            "Requirement already satisfied: certifi in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->semantic-router) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->semantic-router) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->semantic-router) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.22->requests-mock<2.0.0,>=1.12.1->semantic-router) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.22->requests-mock<2.0.0,>=1.12.1->semantic-router) (2.3.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.9.5->semantic-router) (0.2.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: cohere in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (5.13.11)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from cohere) (1.10.0)\n",
            "Requirement already satisfied: httpx>=0.21.2 in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from cohere) (0.28.1)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from cohere) (0.4.0)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from cohere) (2.10.5)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from cohere) (2.27.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from cohere) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from cohere) (0.20.3)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from cohere) (2.32.0.20241016)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from cohere) (4.12.2)\n",
            "Requirement already satisfied: anyio in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from httpx>=0.21.2->cohere) (4.8.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from httpx>=0.21.2->cohere) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from httpx>=0.21.2->cohere) (1.0.7)\n",
            "Requirement already satisfied: idna in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from httpx>=0.21.2->cohere) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.0.0->cohere) (2.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from tokenizers<1,>=0.15->cohere) (0.27.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2024.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.67.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade semantic-router\n",
        "%pip install --upgrade cohere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXFzMk7FIXXU",
        "outputId": "1c0f4ea4-2b2c-4db0-ecbe-0b90295f4ff6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langsmith in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (0.1.147)\n",
            "Collecting langsmith\n",
            "  Using cached langsmith-0.3.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langsmith) (3.10.12)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langsmith) (2.10.5)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langsmith) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from langsmith) (0.23.0)\n",
            "Requirement already satisfied: anyio in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (4.8.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->langsmith) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.7)\n",
            "Requirement already satisfied: idna in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langsmith) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3.0.0,>=2.7.4->langsmith) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3.0.0,>=2.7.4->langsmith) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langsmith) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langsmith) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.3.1)\n",
            "Using cached langsmith-0.3.2-py3-none-any.whl (333 kB)\n",
            "Installing collected packages: langsmith\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.1.147\n",
            "    Uninstalling langsmith-0.1.147:\n",
            "      Successfully uninstalled langsmith-0.1.147\n",
            "Successfully installed langsmith-0.3.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ragas 0.1.9 requires appdirs, which is not installed.\n",
            "langchain-community 0.3.16 requires langchain<0.4.0,>=0.3.16, but you have langchain 0.2.5 which is incompatible.\n",
            "langchain-community 0.3.16 requires langchain-core<0.4.0,>=0.3.32, but you have langchain-core 0.2.9 which is incompatible.\n",
            "langchain-experimental 0.3.4 requires langchain-core<0.4.0,>=0.3.28, but you have langchain-core 0.2.9 which is incompatible.\n",
            "langchain 0.2.5 requires langsmith<0.2.0,>=0.1.17, but you have langsmith 0.3.2 which is incompatible.\n",
            "langchain-core 0.2.9 requires langsmith<0.2.0,>=0.1.75, but you have langsmith 0.3.2 which is incompatible.\n",
            "langchain-groq 0.2.3 requires langchain-core<0.4.0,>=0.3.29, but you have langchain-core 0.2.9 which is incompatible.\n",
            "langchain-pinecone 0.1.1 requires pinecone-client<4.0.0,>=3.2.2, but you have pinecone-client 5.0.1 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "pip install -U langsmith"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "from pathlib import Path\n",
        "\n",
        "# Load path from the environment variable\n",
        "env_ih1 = os.getenv(\"ENV_IH1\")\n",
        "\n",
        "dotenv_path = Path(env_ih1)\n",
        "load_dotenv(dotenv_path=dotenv_path)\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "PINECONE_API_KEY= os.getenv('PINECONE_KEY')\n",
        "SERPAPI_API_KEY = os.getenv('SERPAPI_API_KEY')\n",
        "STEAMSHIP_API_KEY = os.getenv('STEAMSHIP_API_KEY')\n",
        "LANGSMITH_API_KEY = os.getenv('LANGSMITH_API_KEY')\n",
        "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
        "GEMINI_KEY = os.getenv('GEMINI_KEY')\n",
        "\n",
        "os.environ['PATH'] += os.pathsep + '/usr/bin'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NMwEHwM9G1Sc"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from langsmith import wrappers, traceable\n",
        "\n",
        "LANGSMITH_API_KEY= LANGSMITH_API_KEY\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"]=\"memory-project\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohBxmFyTBFT0"
      },
      "source": [
        "### Connect to Pinecone DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LjsIFVbtKBu4"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "from semantic_router.encoders import OpenAIEncoder\n",
        "\n",
        "# os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or getpass(\"OpenAI API key: \")\n",
        "\n",
        "# from dotenv import load_dotenv, find_dotenv\n",
        "import os\n",
        "# _ = load_dotenv(find_dotenv())\n",
        "\n",
        "OPENAI_API_KEY = OPENAI_API_KEY\n",
        "PINECONE_API_KEY = PINECONE_API_KEY\n",
        "\n",
        "encoder = OpenAIEncoder(\n",
        "    name=\"text-embedding-3-small\",\n",
        "    openai_api_key=OPENAI_API_KEY #Get the API key from environment variable\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DIbY89BwOH_x"
      },
      "outputs": [],
      "source": [
        "from pinecone import Pinecone\n",
        "# Initialize Pinecone\n",
        "pinecone = Pinecone(\n",
        "    api_key=PINECONE_API_KEY,  # Replace with your Pinecone API key\n",
        "    environment=\"us-east-1\"  # Replace with your Pinecone environment (e.g., \"us-west1-gcp\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "J233t2I4HmjD"
      },
      "outputs": [],
      "source": [
        "from pinecone import Pinecone\n",
        "\n",
        "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
        "# PINECONE_API_KEY = userdata.get(\"PINECONE_KEY\") or \"YOUR_API_KEY\"\n",
        "\n",
        "# configure client\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-GHzWs3KlJn",
        "outputId": "80e84756-92d7-4915-a173-1508daf1cc3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {'': {'vector_count': 3}},\n",
              " 'total_vector_count': 3}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Connect to the existing index\n",
        "index_name = \"memory-project\"  # Replace with your existing index name\n",
        "# connect to index\n",
        "index = pc.Index(index_name)\n",
        "time.sleep(1)\n",
        "# view index stats\n",
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "actWflaEKgVb"
      },
      "outputs": [],
      "source": [
        "# from pinecone import ServerlessSpec\n",
        "\n",
        "# spec = ServerlessSpec(\n",
        "#     cloud=\"aws\", region=\"us-west-2\"  # us-east-1\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWijfk8LKil7",
        "outputId": "8be19a4b-37e3-4b4c-ab2c-6837da316ad6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1536"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dims = len(encoder([\"some random text\"])[0])\n",
        "dims"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hITmdwQ7Qns0"
      },
      "source": [
        "## Graph State\n",
        "\n",
        "We will define a custom graph state to support our agent-oriented decision making."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "x7Fj9KNjQvUq"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict, Annotated, List, Union\n",
        "from langchain_core.agents import AgentAction, AgentFinish\n",
        "from langchain_core.messages import BaseMessage\n",
        "import operator\n",
        "\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    input: str\n",
        "    chat_history: list[BaseMessage]\n",
        "    intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp4uQFBKQdyI"
      },
      "source": [
        "There are four parts to our agent state, those are:\n",
        "\n",
        "* `input`: this is the user's most recent query, usually this would be a question that we want to answer with our research agent.\n",
        "* `chat_history`: we are building a conversational agent that can support multiple interactions, to allow previous interactions to provide additional context throughout our agent logic we include the chat history in the agent state.\n",
        "* `intermediate_steps`: provides a record of all steps the research agent will take between the user asking a question via `input` and the agent providing a final answer. This can include things like \"search arxiv\", \"perform general purpose web search\", etc. These intermediate steps are crucial to allowing the agent to follow a path of coherent actions and ultimately producing an informed final answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlVbgX39Rhxj"
      },
      "source": [
        "## Custom Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jpYR2DYsHtgb"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'ToolOutputMixin' from 'langchain_core.messages.tool' (c:\\Users\\aurel\\OneDrive\\Documents\\Python\\IronHack\\W8\\D2\\lab-langsmith-summarizations\\.conda\\Lib\\site-packages\\langchain_core\\messages\\tool.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tool\n",
            "File \u001b[1;32mc:\\Users\\aurel\\OneDrive\\Documents\\Python\\IronHack\\W8\\D2\\lab-langsmith-summarizations\\.conda\\Lib\\site-packages\\langchain_core\\tools\\__init__.py:22\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"**Tools** are classes that an Agent uses to interact with the world.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mEach tool has a **description**. Agent uses the description to choose the right\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    CallbackManagerForToolRun, AsyncCallbackManagerForToolRun\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     FILTERED_ARGS \u001b[38;5;28;01mas\u001b[39;00m FILTERED_ARGS,\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     26\u001b[0m     BaseTool \u001b[38;5;28;01mas\u001b[39;00m BaseTool,\n\u001b[0;32m     27\u001b[0m )\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     29\u001b[0m     BaseToolkit \u001b[38;5;28;01mas\u001b[39;00m BaseToolkit,\n\u001b[0;32m     30\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\aurel\\OneDrive\\Documents\\Python\\IronHack\\W8\\D2\\lab-langsmith-summarizations\\.conda\\Lib\\site-packages\\langchain_core\\tools\\base.py:48\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     43\u001b[0m     AsyncCallbackManager,\n\u001b[0;32m     44\u001b[0m     BaseCallbackManager,\n\u001b[0;32m     45\u001b[0m     CallbackManager,\n\u001b[0;32m     46\u001b[0m     Callbacks,\n\u001b[0;32m     47\u001b[0m )\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ToolCall, ToolMessage, ToolOutputMixin\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     RunnableConfig,\n\u001b[0;32m     51\u001b[0m     RunnableSerializable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m     run_in_executor,\n\u001b[0;32m     55\u001b[0m )\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _set_config_context\n",
            "\u001b[1;31mImportError\u001b[0m: cannot import name 'ToolOutputMixin' from 'langchain_core.messages.tool' (c:\\Users\\aurel\\OneDrive\\Documents\\Python\\IronHack\\W8\\D2\\lab-langsmith-summarizations\\.conda\\Lib\\site-packages\\langchain_core\\messages\\tool.py)"
          ]
        }
      ],
      "source": [
        "from langchain_core.tools import tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uydhqzKIU2F"
      },
      "source": [
        "Let's test the tool."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLX1N7oWKiNZ"
      },
      "source": [
        "### Web Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsOutTz9KjoL"
      },
      "source": [
        "The web search tool will provide the agent with access to web search. It will be instructed to use this for more general knowledge queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vuv_exwsH8ZJ"
      },
      "outputs": [],
      "source": [
        "from serpapi import GoogleSearch\n",
        "\n",
        "serpapi_params = {\n",
        "    \"engine\": \"google\",\n",
        "    \"api_key\": SERPAPI_API_KEY\n",
        "}\n",
        "\n",
        "search = GoogleSearch({\n",
        "    **serpapi_params,\n",
        "    \"q\": \"coffee\"\n",
        "})\n",
        "\n",
        "results = search.get_dict()[\"organic_results\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KklJP-XSTqLG"
      },
      "outputs": [],
      "source": [
        "contexts = \"\\n---\\n\".join(\n",
        "    [\"\\n\".join([x[\"title\"], x[\"snippet\"], x[\"link\"]]) for x in results]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_b083gU3T-8K",
        "outputId": "3535f58b-8c83-429d-a3dc-f588aa2442ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coffee\n",
            "Coffee is a beverage brewed from roasted, ground coffee beans. Darkly colored, bitter, and slightly acidic, coffee has a stimulating effect on humans, ...\n",
            "https://en.wikipedia.org/wiki/Coffee\n",
            "---\n",
            "Arabica Coffee Prices Hit New High on U.S., Colombia ...\n",
            "Continuous arabica coffee futures on the ICE were up 0.1% at $3.48 a pound in volatile evening trading in Europe, though they are up more than ...\n",
            "https://www.wsj.com/economy/trade/arabica-coffee-prices-hit-new-high-on-u-s-colombia-tariff-spat-582446fe\n",
            "---\n",
            "r/Coffee\n",
            "thread where you can share what you are brewing or ask for bean recommendations. This is a place to share and talk about your favorite coffee roasters or beans.\n",
            "https://www.reddit.com/r/Coffee/\n",
            "---\n",
            "Starbucks Coffee Company\n",
            "More than just great coffee. Explore the menu, sign up for Starbucks® Rewards, manage your gift card and more.\n",
            "https://www.starbucks.com/\n",
            "---\n",
            "Best Rated Coffee Online - Whole Bean & Ground Coffee\n",
            "Don't look anywhere else to find the best-rated coffee online. Caruso's Coffee offers a collection of light, medium, and dark roast options. Shop today.\n",
            "https://shop.carusoscoffee.com/collections/coffee?srsltid=AfmBOorzF4VK447xQzGtDWDnKwOSSFSf1TovMkMTFRMEYqCG6ihIoaFz\n",
            "---\n",
            "Blue Bottle Coffee | Fresh Roasted Specialty Coffee\n",
            "Blue Bottle Coffee is a specialty coffee roaster with cafes in LA, SF, NYC, & Japan. Shop our freshly roasted specialty coffee online & in-store.\n",
            "https://bluebottlecoffee.com/?srsltid=AfmBOorZuyg1owNFrn85YtCHUINz_XZ9g24GOb3HEAWzsUXNk-ePN9pS\n",
            "---\n",
            "9 Reasons Why (the Right Amount of) Coffee Is Good for You\n",
            "Drinking one to two cups of coffee a day may help ward off heart failure, when a weakened heart has difficulty pumping enough blood to the body.\n",
            "https://www.hopkinsmedicine.org/health/wellness-and-prevention/9-reasons-why-the-right-amount-of-coffee-is-good-for-you\n"
          ]
        }
      ],
      "source": [
        "print(contexts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtmOt4nQH4KS"
      },
      "source": [
        "We put this process into a tool:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TYmOL54xH6GH"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'ToolOutputMixin' from 'langchain_core.messages.tool' (c:\\Users\\aurel\\OneDrive\\Documents\\Python\\IronHack\\W8\\D2\\lab-langsmith-summarizations\\.conda\\Lib\\site-packages\\langchain_core\\messages\\tool.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tool\n\u001b[0;32m      3\u001b[0m \u001b[38;5;129m@tool\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_search\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mweb_search\u001b[39m(query: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Finds general knowledge information using Google search. Can also be used\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m    to augment more 'general' knowledge to a previous specialist query.\"\"\"\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\aurel\\OneDrive\\Documents\\Python\\IronHack\\W8\\D2\\lab-langsmith-summarizations\\.conda\\Lib\\site-packages\\langchain_core\\tools\\__init__.py:22\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"**Tools** are classes that an Agent uses to interact with the world.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mEach tool has a **description**. Agent uses the description to choose the right\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    CallbackManagerForToolRun, AsyncCallbackManagerForToolRun\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     FILTERED_ARGS \u001b[38;5;28;01mas\u001b[39;00m FILTERED_ARGS,\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     26\u001b[0m     BaseTool \u001b[38;5;28;01mas\u001b[39;00m BaseTool,\n\u001b[0;32m     27\u001b[0m )\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     29\u001b[0m     BaseToolkit \u001b[38;5;28;01mas\u001b[39;00m BaseToolkit,\n\u001b[0;32m     30\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\aurel\\OneDrive\\Documents\\Python\\IronHack\\W8\\D2\\lab-langsmith-summarizations\\.conda\\Lib\\site-packages\\langchain_core\\tools\\base.py:48\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     43\u001b[0m     AsyncCallbackManager,\n\u001b[0;32m     44\u001b[0m     BaseCallbackManager,\n\u001b[0;32m     45\u001b[0m     CallbackManager,\n\u001b[0;32m     46\u001b[0m     Callbacks,\n\u001b[0;32m     47\u001b[0m )\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ToolCall, ToolMessage, ToolOutputMixin\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     RunnableConfig,\n\u001b[0;32m     51\u001b[0m     RunnableSerializable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m     run_in_executor,\n\u001b[0;32m     55\u001b[0m )\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _set_config_context\n",
            "\u001b[1;31mImportError\u001b[0m: cannot import name 'ToolOutputMixin' from 'langchain_core.messages.tool' (c:\\Users\\aurel\\OneDrive\\Documents\\Python\\IronHack\\W8\\D2\\lab-langsmith-summarizations\\.conda\\Lib\\site-packages\\langchain_core\\messages\\tool.py)"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Install the missing package\n",
        "%pip install langchain_core\n",
        "\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool(\"web_search\")\n",
        "def web_search(query: str):\n",
        "    \"\"\"Finds general knowledge information using Google search. Can also be used\n",
        "    to augment more 'general' knowledge to a previous specialist query.\"\"\"\n",
        "    search = GoogleSearch({\n",
        "        **serpapi_params,\n",
        "        \"q\": query,\n",
        "        \"num\": 5\n",
        "    })\n",
        "    results = search.get_dict()[\"organic_results\"]\n",
        "    contexts = \"\\n---\\n\".join(\n",
        "        [\"\\n\".join([x[\"title\"], x[\"snippet\"], x[\"link\"]]) for x in results]\n",
        "    )\n",
        "    return contexts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCBZjWfAIN0N"
      },
      "source": [
        "### RAG Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY37AFP6RBOP"
      },
      "source": [
        "We provide two RAG-focused tools for our agent. The `rag_search` allows the agent to perform a simple RAG search for some information across _all_ indexed research papers. The `rag_search_filter` also searches, but _within_ a specific paper which is filtered for via the `arxiv_id` parameter.\n",
        "\n",
        "We also define the `format_rag_contexts` function to handle the transformation of our Pinecone results from a JSON object to a readble plaintext format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "id": "SPcrbQfdRrda"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "\n",
        "def format_rag_contexts(matches: list):\n",
        "    contexts = []\n",
        "    for x in matches:\n",
        "        text = (\n",
        "            f\"Doc name: {x['metadata']['Doc name']}\\n\"\n",
        "            f\"Author: {x['metadata']['Author']}\\n\"\n",
        "            f\"Summary: {x['metadata']['Summary']}\\n\"\n",
        "            f\"Chunks: {x['metadata']['Chunks']}\\n\"\n",
        "        )\n",
        "        contexts.append(text)\n",
        "    context_str = \"\\n---\\n\".join(contexts)\n",
        "    return context_str\n",
        "\n",
        "\n",
        "\n",
        "@tool(\"rag_search\")\n",
        "def rag_search(query: str):\n",
        "    \"\"\"Finds related information using a natural language query in the family history.\"\"\"\n",
        "    xq = encoder([query])\n",
        "    xc = index.query(vector=xq, top_k=5, include_metadata=True)\n",
        "    context_str = format_rag_contexts(xc[\"matches\"])\n",
        "    return context_str\n",
        "\n",
        "@tool(\"rag_search_filter\")\n",
        "def rag_search_filter(query: str, author: str):\n",
        "    \"\"\"Finds related information using a natural language query in the family history given an author.\"\"\"\n",
        "    xq = encoder([query])\n",
        "    xc = index.query(vector=xq, top_k=3, include_metadata=True, filter={\"Author\": author})\n",
        "    context_str = format_rag_contexts(xc[\"matches\"])\n",
        "    return context_str\n",
        "\n",
        "@tool(\"rag_search\")\n",
        "def rag_search(query: str):\n",
        "    \"\"\"Finds specialist information on AI using a natural language query.\"\"\"\n",
        "    xq = encoder([query])\n",
        "    xc = index.query(vector=xq, top_k=2, include_metadata=True)\n",
        "    context_str = format_rag_contexts(xc[\"matches\"])\n",
        "    return context_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "W36mGme-f7Jb",
        "outputId": "b350afc1-2088-4c99-f1c9-68c21f707ec7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Doc name: Pdf img\\nAuthor: John Doe\\nSummary: Isaac, souvent appelé Louis, est l\\'ancêtre direct né en 1766 à Froeningen, marié à Rachel Gugenheim (1772-1843). Ils ont eu six enfants, dont Lehmann (Clément), né en 1800, qui a épousé Athelle Bloch en 1827. Ils ont eu neuf enfants, parmi lesquels Jacques Dreyfus, né le 9 janvier 1829, qui a épousé Catherine Lévy en 1860 et est décédé en 1893. Jacques, colporteur de tissus, a joué un rôle significatif dans la famille, voyageant pour approvisionner des revendeurs dans des bourgs non desservis.\\nChunks: 118.0\\n\\n---\\nDoc name: La belle au bois dormant\\nAuthor: Perrault\\nSummary: In \"La Belle au Bois Dormant,\" a princess pricks her finger on a spindle, falling into a deep sleep as foretold by the fairies. Despite efforts to revive her, she remains unconscious. The king places her in a beautifully adorned chamber, where she appears angelic, still breathing but unresponsive. He decides to let her sleep until the time of her awakening. Meanwhile, a good fairy, who had previously saved her life by cursing her to sleep for a hundred years, learns of the incident through a dwarf with magical boots.\\nChunks: 3.0\\n'"
            ]
          },
          "execution_count": 210,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_search.run(\"Who is Dreyfus?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDBmpJ0URzKS"
      },
      "source": [
        "### Final Answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWVKYuQ6R6nB"
      },
      "source": [
        "Finally, we define a \"final answer\" tool. This isn't a tool in the usual sense, instead we use it to force a particular output format from our LLM via the function/tool calling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "id": "UIjAlcHdfJCG"
      },
      "outputs": [],
      "source": [
        "@tool(\"final_answer\")\n",
        "def final_answer(\n",
        "    introduction: str,\n",
        "    research_steps: str,\n",
        "    main_body: str,\n",
        "    conclusion: str,\n",
        "    sources: Union[str, List[str], None] = None\n",
        "):\n",
        "    \"\"\"\n",
        "    You are the family safe, keeper of the family collective memory.\n",
        "\n",
        "    Returns a natural language response to the user iquestion based on the family memory database.\n",
        "\n",
        "    Do not invent anything but you are allowed to link information together from multiple sources.\n",
        "\n",
        "    If you can't find an answer with {\"tool\": \"rag_search\"}, just say that you don't know.\n",
        "    \"\"\"\n",
        "    if type(research_steps) is list:\n",
        "        research_steps = \"\\n\".join([f\"- {r}\" for r in research_steps])\n",
        "    if type(sources) is list:\n",
        "        sources = \"\\n\".join([f\"- {s}\" for s in sources])\n",
        "    return \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.messages import SystemMessage, AIMessage\n",
        "\n",
        "@tool(\"final_answer\")\n",
        "def final_answer(\n",
        "    introduction: str,\n",
        "    research_steps: str,\n",
        "    main_body: str,\n",
        "    conclusion: str,\n",
        "    sources: Union[str, List[str], None] = None\n",
        "):\n",
        "    \"\"\"\n",
        "    You are the family safe, keeper of the family collective memory.\n",
        "\n",
        "    Returns a natural language response to the user's question based on the family memory database.\n",
        "\n",
        "    Do not invent anything but you are allowed to link information together from multiple sources.\n",
        "\n",
        "    If you can't find an answer with sources from {\"tool\": \"rag_search\"}, just say that you don't know.\n",
        "    \"\"\"\n",
        "\n",
        "    # Format the research steps and sources\n",
        "    if isinstance(research_steps, list):\n",
        "        research_steps = \"\\n\".join([f\"- {r}\" for r in research_steps])\n",
        "    if isinstance(sources, list):\n",
        "        sources = \"\\n\".join([f\"- {s}\" for s in sources])\n",
        "\n",
        "    # System prompt to guide the final response\n",
        "    system_prompt = SystemMessage(\n",
        "        content=(\n",
        "            \"You are the family safe, the guardian of collective memory. \"\n",
        "            \"Provide a detailed but concise summary based on the following sections: \"\n",
        "            \"introduction, research steps, main body, and conclusion. \"\n",
        "            \"Include sources if available and only use verified information.\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Combine the sections into a message\n",
        "    user_query_context = (\n",
        "        f\"### Introduction:\\n{introduction}\\n\\n\"\n",
        "        f\"### Research Steps:\\n{research_steps}\\n\\n\"\n",
        "        f\"### Main Body:\\n{main_body}\\n\\n\"\n",
        "        f\"### Conclusion:\\n{conclusion}\\n\\n\"\n",
        "        f\"### Sources:\\n{sources if sources else 'No sources available.'}\"\n",
        "    )\n",
        "\n",
        "    # Append the system prompt to messages and call the LLM\n",
        "    messages = [system_prompt, AIMessage(content=user_query_context)]\n",
        "    final_response = llm.invoke(messages)  # Call the LLM for a response\n",
        "\n",
        "    return final_response\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8OsQ3tIS-_t"
      },
      "source": [
        "## Initialize the \"Oracle\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YykLRD5rXfr5"
      },
      "source": [
        "The **Oracle** LLM is our graph's decision maker. It decides which path we should take down our graph. It functions similarly to an agent but is much simpler and reliable.\n",
        "\n",
        "The Oracle consists of an LLM provided with a set of potential function calls (ie our tools) that it can decide to use — we force it to use _at least_ one of those tool using the `tool_choice=\"any\"` setting (see below). Our Oracle only makes the decision to use a tool, it doesn't execute the tool code itself (we do that seperately in our graph)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRlREI1wYSd0"
      },
      "source": [
        "### Oracle Prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFE638_CYUbf"
      },
      "source": [
        "Our prompt for the Oracle will emphasize it's decision making ability within the `system_prompt`, leave a placeholder for us to later insert `chat_history`, and provide a place for us to insert the user `input`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 298,
      "metadata": {
        "id": "FBZrvHDAYmOP"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "system_prompt = \"\"\"You are the Family Safe, keeper of the family's collective memory. \n",
        "Your role is to decide how to handle user queries using the available tools.\n",
        "\n",
        "**Tool Usage:**\n",
        "- Do NOT reuse a tool for the same query (check the scratchpad).\n",
        "- Do NOT use any tool more than **twice**.\n",
        "- Prioritize **rag_search** for gathering information.\n",
        "- Use **web_search** only for additional historical context.\n",
        "\n",
        "**Response Protocol:**\n",
        "- If **rag_search** provides no answer, state: \"I don't know.\"\n",
        "- NEVER invent information or use data beyond the family memory.\n",
        "- Always provide sources via the **final_answer** tool.\n",
        "\n",
        "By following these rules, you ensure accurate and responsible responses.\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_prompt),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "    (\"assistant\", \"scratchpad: {scratchpad}\"),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euGh0137Ynxv"
      },
      "source": [
        "Next, we must initialize our `llm` (for this we use `gpt-4o`) and then create the _runnable_ pipeline of our Oracle.\n",
        "\n",
        "The runnable connects our inputs (the user `input` and `chat_history`) to our `prompt`, and our `prompt` to our `llm`. It is also where we _bind_ our tools to the LLM and enforce function calling via `tool_choice=\"any\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 299,
      "metadata": {
        "id": "0gKxRe4tTBHX"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import ToolCall, ToolMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    openai_api_key = OPENAI_API_KEY,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "tools=[\n",
        "    rag_search_filter,\n",
        "    rag_search,\n",
        "    # web_search,\n",
        "    final_answer\n",
        "]\n",
        "\n",
        "# define a function to transform intermediate_steps from list\n",
        "# of AgentAction to scratchpad string\n",
        "def create_scratchpad(intermediate_steps: list[AgentAction]):\n",
        "    research_steps = []\n",
        "    for i, action in enumerate(intermediate_steps):\n",
        "        if action.log != \"TBD\":\n",
        "            # this was the ToolExecution\n",
        "            research_steps.append(\n",
        "                f\"Tool: {action.tool}, input: {action.tool_input}\\n\"\n",
        "                f\"Output: {action.log}\"\n",
        "            )\n",
        "    return \"\\n---\\n\".join(research_steps)\n",
        "\n",
        "oracle = (\n",
        "    {\n",
        "        \"input\": lambda x: x[\"input\"],\n",
        "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
        "        \"scratchpad\": lambda x: create_scratchpad(\n",
        "            intermediate_steps=x[\"intermediate_steps\"]\n",
        "        ),\n",
        "    }\n",
        "    | prompt\n",
        "    | llm.bind_tools(tools, tool_choice=\"any\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESCSupKbTuVR"
      },
      "source": [
        "Test the agent quickly to confirm it is functional:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 300,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5xMQ8ajTxFQ",
        "outputId": "79d202a0-561c-4d2c-9358-fd659df9a0a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_qpczlLaIXRz6805hsr6Yylh6', 'function': {'arguments': '{\"query\":\"interesting facts\",\"author\":\"Dreyfus family\"}', 'name': 'rag_search_filter'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 358, 'total_tokens': 383, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-4c94be86-9884-4b75-bbb3-1b75507f53d6-0', tool_calls=[{'name': 'rag_search_filter', 'args': {'query': 'interesting facts', 'author': 'Dreyfus family'}, 'id': 'call_qpczlLaIXRz6805hsr6Yylh6', 'type': 'tool_call'}], usage_metadata={'input_tokens': 358, 'output_tokens': 25, 'total_tokens': 383, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 300,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = {\n",
        "    \"input\": \"tell me something interesting about the Dreyfus family\",\n",
        "    \"chat_history\": [],\n",
        "    \"intermediate_steps\": [],\n",
        "}\n",
        "out = oracle.invoke(inputs)\n",
        "out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTwZ-7ZtZXq2"
      },
      "source": [
        "It is running but we are returning a lot of output here, we can narrow this down to what we need — ie, the chosen tool name and generated input args for the tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "u7wUMr2BUBt7",
        "outputId": "8cb7c1c4-cadf-42c2-b4fe-fde0b84cf8d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'rag_search_filter'"
            ]
          },
          "execution_count": 301,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out.tool_calls[0][\"name\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 302,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "se0M1pbnaFyi",
        "outputId": "1b2bfe34-6adc-4485-c5fc-81d56bc2eae0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query': 'interesting facts', 'author': 'Dreyfus family'}"
            ]
          },
          "execution_count": 302,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out.tool_calls[0][\"args\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbO6IMEZaK4q"
      },
      "source": [
        "We can see now that our Oracle decided to use the `web_search` tool with a `query` of `\"interesting facts about dogs\"` — a good choice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6pAxC9kcY1F"
      },
      "source": [
        "## Define Nodes for Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8ykjVWoa0kz"
      },
      "source": [
        "We will be passing the tool use decision to our `router` which will _route_ the output to the chosen node component to run (we define these below) based on the `out.tool_calls[0][\"name\"]` value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "metadata": {
        "id": "LcRVPIuAgcoG"
      },
      "outputs": [],
      "source": [
        "def run_oracle(state: list):\n",
        "    print(\"run_oracle\")\n",
        "    print(f\"intermediate_steps: {state['intermediate_steps']}\")\n",
        "    out = oracle.invoke(state)\n",
        "    tool_name = out.tool_calls[0][\"name\"]\n",
        "    tool_args = out.tool_calls[0][\"args\"]\n",
        "    action_out = AgentAction(\n",
        "        tool=tool_name,\n",
        "        tool_input=tool_args,\n",
        "        log=\"TBD\"\n",
        "    )\n",
        "    return {\n",
        "        \"intermediate_steps\": [action_out]\n",
        "    }\n",
        "\n",
        "def router (state: list): #Original\n",
        "    # return the tool name to use\n",
        "    if isinstance(state[\"intermediate_steps\"], list):\n",
        "        return state[\"intermediate_steps\"][-1].tool\n",
        "    else:\n",
        "        # if we output bad format go to final answer\n",
        "        print(\"Router invalid format\")\n",
        "#         return \"final_answer\"\n",
        "    \n",
        "# def router(state: list):\n",
        "#     if isinstance(state[-1].get(\"intermediate_steps\"), list):  # Access the last state entry\n",
        "#         # Return the tool name from the last intermediate step\n",
        "#         return state[-1][\"intermediate_steps\"][-1][\"tool\"]\n",
        "#     else:\n",
        "#         # Handle invalid format or empty intermediate steps\n",
        "#         print(\"Router: Invalid or missing intermediate steps. Routing to final_answer.\")\n",
        "#         return \"final_answer\"  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtBEhoDOSOCQ"
      },
      "source": [
        "All of our tools can be run using the same function logic, which we define with `run_tool`. The input parameters to our tool call and the resultant output are added to our graph state's `intermediate_steps` parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "kkxxHFwgSVIs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {
        "id": "-JGJGvDVcbvq"
      },
      "outputs": [],
      "source": [
        "tool_str_to_func = {\n",
        "    \"rag_search_filter\": rag_search_filter,\n",
        "    \"rag_search\": rag_search,\n",
        "    # \"fetch_arxiv\": fetch_arxiv,\n",
        "    # \"web_search\": web_search,\n",
        "    \"final_answer\": final_answer\n",
        "}\n",
        "\n",
        "def run_tool(state: list):\n",
        "    # use this as helper function so we repeat less code\n",
        "    tool_name = state[\"intermediate_steps\"][-1].tool\n",
        "    tool_args = state[\"intermediate_steps\"][-1].tool_input\n",
        "    print(f\"{tool_name}.invoke(input={tool_args})\")\n",
        "    # run tool\n",
        "    out = tool_str_to_func[tool_name].invoke(input=tool_args)\n",
        "    action_out = AgentAction(\n",
        "        tool=tool_name,\n",
        "        tool_input=tool_args,\n",
        "        log=str(out)\n",
        "    )\n",
        "    return {\"intermediate_steps\": [action_out]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwv4EsTKeZzh"
      },
      "source": [
        "## Define Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 305,
      "metadata": {
        "id": "LAkcBE5pebXv"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "graph = StateGraph(AgentState)\n",
        "\n",
        "graph.add_node(\"oracle\", run_oracle)\n",
        "graph.add_node(\"rag_search_filter\", run_tool)\n",
        "graph.add_node(\"rag_search\", run_tool)\n",
        "# graph.add_node(\"fetch_arxiv\", run_tool)\n",
        "# graph.add_node(\"web_search\", run_tool)\n",
        "graph.add_node(\"final_answer\", run_tool)\n",
        "\n",
        "graph.set_entry_point(\"oracle\")\n",
        "\n",
        "graph.add_conditional_edges(\n",
        "    source=\"oracle\",  # where in graph to start\n",
        "    path=router,  # function to determine which node is called\n",
        ")\n",
        "\n",
        "# create edges from each tool back to the oracle\n",
        "for tool_obj in tools:\n",
        "    if tool_obj.name != \"final_answer\":\n",
        "        graph.add_edge(tool_obj.name, \"oracle\")\n",
        "\n",
        "# if anything goes to final answer, it must then move to END\n",
        "graph.add_edge(\"final_answer\", END)\n",
        "\n",
        "runnable = graph.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 312,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain_core in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (0.2.9)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langchain_core) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from langchain_core) (0.1.147)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langchain_core) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langchain_core) (2.10.5)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from langchain_core) (8.5.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain_core) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain_core) (3.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain_core) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain_core) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain_core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain_core) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain_core) (4.12.2)\n",
            "Requirement already satisfied: anyio in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain_core) (4.8.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain_core) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain_core) (1.0.7)\n",
            "Requirement already satisfied: idna in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain_core) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain_core) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain_core) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain_core) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\aurel\\onedrive\\documents\\python\\ironhack\\w8\\d2\\lab-langsmith-summarizations\\.conda\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain_core) (1.3.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install the missing package\n",
        "%pip install langchain_core"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 313,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_core.runnables.graph_mermaid'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[313], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StateGraph, START, END\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image, display\n\u001b[1;32m----> 6\u001b[0m display(Image(\u001b[43mrunnable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\runnables\\graph.py:623\u001b[0m, in \u001b[0;36mGraph.draw_mermaid_png\u001b[1;34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_mermaid_png\u001b[39m(\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    597\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    604\u001b[0m     padding: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m    605\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbytes\u001b[39m:\n\u001b[0;32m    606\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Draw the graph as a PNG image using Mermaid.\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \n\u001b[0;32m    608\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;124;03m        The PNG image as bytes.\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 623\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_mermaid\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m draw_mermaid_png\n\u001b[0;32m    625\u001b[0m     mermaid_syntax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_mermaid(\n\u001b[0;32m    626\u001b[0m         curve_style\u001b[38;5;241m=\u001b[39mcurve_style,\n\u001b[0;32m    627\u001b[0m         node_colors\u001b[38;5;241m=\u001b[39mnode_colors,\n\u001b[0;32m    628\u001b[0m         wrap_label_n_words\u001b[38;5;241m=\u001b[39mwrap_label_n_words,\n\u001b[0;32m    629\u001b[0m     )\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m draw_mermaid_png(\n\u001b[0;32m    631\u001b[0m         mermaid_syntax\u001b[38;5;241m=\u001b[39mmermaid_syntax,\n\u001b[0;32m    632\u001b[0m         output_file_path\u001b[38;5;241m=\u001b[39moutput_file_path,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    635\u001b[0m         padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m    636\u001b[0m     )\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain_core.runnables.graph_mermaid'"
          ]
        }
      ],
      "source": [
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from IPython.display import Image, display\n",
        "\n",
        "\n",
        "display(Image(runnable.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "EmwkoQkthb__",
        "outputId": "62a76d07-3576-498a-cf53-a1cb4dad57cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pygraphviz==1.12Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "  Downloading pygraphviz-1.12.tar.gz (104 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Building wheels for collected packages: pygraphviz\n",
            "  Building wheel for pygraphviz (pyproject.toml): started\n",
            "  Building wheel for pygraphviz (pyproject.toml): finished with status 'error'\n",
            "Failed to build pygraphviz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × Building wheel for pygraphviz (pyproject.toml) did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [51 lines of output]\n",
            "      running bdist_wheel\n",
            "      running build\n",
            "      running build_py\n",
            "      creating build\\lib.win-amd64-cpython-312\\pygraphviz\n",
            "      copying pygraphviz\\agraph.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\n",
            "      copying pygraphviz\\graphviz.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\n",
            "      copying pygraphviz\\scraper.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\n",
            "      copying pygraphviz\\testing.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\n",
            "      copying pygraphviz\\__init__.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\n",
            "      creating build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_attribute_defaults.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_clear.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_close.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_drawing.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_edge_attributes.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_graph.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_html.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_layout.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_node_attributes.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_readwrite.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_repr_mimebundle.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_scraper.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_string.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_subgraph.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_unicode.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\__init__.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      running egg_info\n",
            "      writing pygraphviz.egg-info\\PKG-INFO\n",
            "      writing dependency_links to pygraphviz.egg-info\\dependency_links.txt\n",
            "      writing top-level names to pygraphviz.egg-info\\top_level.txt\n",
            "      reading manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n",
            "      reading manifest template 'MANIFEST.in'\n",
            "      warning: no files found matching '*.png' under directory 'doc'\n",
            "      warning: no files found matching '*.html' under directory 'doc'\n",
            "      warning: no files found matching '*.txt' under directory 'doc'\n",
            "      warning: no files found matching '*.css' under directory 'doc'\n",
            "      warning: no previously-included files matching '*~' found anywhere in distribution\n",
            "      warning: no previously-included files matching '*.pyc' found anywhere in distribution\n",
            "      warning: no previously-included files matching '.svn' found anywhere in distribution\n",
            "      no previously-included directories found matching 'doc\\build'\n",
            "      adding license file 'LICENSE'\n",
            "      writing manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n",
            "      copying pygraphviz\\graphviz.i -> build\\lib.win-amd64-cpython-312\\pygraphviz\n",
            "      copying pygraphviz\\graphviz_wrap.c -> build\\lib.win-amd64-cpython-312\\pygraphviz\n",
            "      running build_ext\n",
            "      building 'pygraphviz._graphviz' extension\n",
            "      creating build\\temp.win-amd64-cpython-312\\Release\\pygraphviz\n",
            "      \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.42.34433\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -DSWIG_PYTHON_STRICT_BYTE_CHAR -DGVDLL -Ic:\\Users\\aurel\\OneDrive\\Documents\\Python\\IronHack\\W8\\D2\\lab-langsmith-summarizations\\.conda\\include -Ic:\\Users\\aurel\\OneDrive\\Documents\\Python\\IronHack\\W8\\D2\\lab-langsmith-summarizations\\.conda\\Include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.42.34433\\include\" \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Auxiliary\\VS\\include\" /Tcpygraphviz/graphviz_wrap.c /Fobuild\\temp.win-amd64-cpython-312\\Release\\pygraphviz\\graphviz_wrap.obj\n",
            "      graphviz_wrap.c\n",
            "      c:\\Users\\aurel\\OneDrive\\Documents\\Python\\IronHack\\W8\\D2\\lab-langsmith-summarizations\\.conda\\include\\pyconfig.h(59): fatal error C1083: Impossible d'ouvrir le fichier includeÿ: 'io.h'ÿ: No such file or directory\n",
            "      error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2022\\\\BuildTools\\\\VC\\\\Tools\\\\MSVC\\\\14.42.34433\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  ERROR: Failed building wheel for pygraphviz\n",
            "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pygraphviz)\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "Install pygraphviz to draw graphs: `pip install pygraphviz`.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\runnables\\graph_png.py:136\u001b[0m, in \u001b[0;36mPngDrawer.draw\u001b[1;34m(self, graph, output_path)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpygraphviz\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpgv\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pygraphviz'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[61], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstall pygraphviz==1.12\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m----> 6\u001b[0m Image(\u001b[43mrunnable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\runnables\\graph.py:556\u001b[0m, in \u001b[0;36mGraph.draw_png\u001b[1;34m(self, output_file_path, fontname, labels)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_png\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PngDrawer\n\u001b[0;32m    545\u001b[0m default_node_labels \u001b[38;5;241m=\u001b[39m {node\u001b[38;5;241m.\u001b[39mid: node\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mvalues()}\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPngDrawer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfontname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43mLabelsDict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdefault_node_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnodes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43medges\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43medges\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m--> 556\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\runnables\\graph_png.py:139\u001b[0m, in \u001b[0;36mPngDrawer.draw\u001b[1;34m(self, graph, output_path)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    138\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstall pygraphviz to draw graphs: `pip install pygraphviz`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# Create a directed graph\u001b[39;00m\n\u001b[0;32m    142\u001b[0m viz \u001b[38;5;241m=\u001b[39m pgv\u001b[38;5;241m.\u001b[39mAGraph(directed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, nodesep\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, ranksep\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
            "\u001b[1;31mImportError\u001b[0m: Install pygraphviz to draw graphs: `pip install pygraphviz`."
          ]
        }
      ],
      "source": [
        "# Install pygraphviz\n",
        "%pip install pygraphviz==1.12 \n",
        "\n",
        "from IPython.display import Image\n",
        "\n",
        "Image(runnable.get_graph().draw_png())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmrXAdCwiN8N"
      },
      "source": [
        "## Building Reports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPJiet2niPnQ"
      },
      "source": [
        "Let's test our research agent. First, I want to try on something simple (although not within the intended use-case of our agent):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 306,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eghr8ZBI-IJL",
        "outputId": "7716c309-5ef8-4a95-8a93-0383c3a1140b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "run_oracle\n",
            "intermediate_steps: []\n",
            "rag_search.invoke(input={'query': 'Dreyfus'})\n",
            "run_oracle\n",
            "intermediate_steps: [AgentAction(tool='rag_search', tool_input={'query': 'Dreyfus'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'Dreyfus'}, log='Doc name: Pdf img\\nAuthor: John Doe\\nSummary: Isaac, souvent appelé Louis, est l\\'ancêtre direct né en 1766 à Froeningen, marié à Rachel Gugenheim (1772-1843). Ils ont eu six enfants, dont Lehmann (Clément), né en 1800, qui a épousé Athelle Bloch en 1827. Ils ont eu neuf enfants, parmi lesquels Jacques Dreyfus, né le 9 janvier 1829, qui a épousé Catherine Lévy en 1860 et est décédé en 1893. Jacques, colporteur de tissus, a joué un rôle significatif dans la famille, voyageant pour approvisionner des revendeurs dans des bourgs non desservis.\\nChunks: 118.0\\n\\n---\\nDoc name: La belle au bois dormant\\nAuthor: Perrault\\nSummary: In \"La Belle au Bois Dormant,\" a princess pricks her finger on a spindle, falling into a deep sleep as foretold by the fairies. Despite efforts to revive her, she remains unconscious. The king places her in a beautifully adorned chamber, where she appears angelic, still breathing but unresponsive. He decides to let her sleep until the time of her awakening. Meanwhile, a good fairy, who had previously saved her life by cursing her to sleep for a hundred years, learns of the incident through a dwarf with magical boots.\\nChunks: 3.0\\n')]\n",
            "final_answer.invoke(input={'introduction': 'The name Dreyfus is associated with a significant figure in family history.', 'research_steps': 'I searched for information regarding Dreyfus in the family memory database.', 'main_body': \"Jacques Dreyfus, born on January 9, 1829, is a notable ancestor in the family lineage. He was a cloth peddler who played an important role in the family's economic activities by traveling to supply retailers in underserved towns. He married Catherine Lévy in 1860 and passed away in 1893. His lineage traces back to Isaac, often referred to as Louis, who was born in 1766 and married Rachel Gugenheim.\", 'conclusion': \"Jacques Dreyfus's contributions to the family and his role as a cloth peddler highlight the family's historical significance in trade and commerce.\", 'sources': 'family memory database'})\n"
          ]
        }
      ],
      "source": [
        "out = runnable.invoke({\n",
        "    \"input\": \"Who is Dreyfus?\",\n",
        "    \"chat_history\": [],\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjwDv5zvjACg"
      },
      "source": [
        "Let's create a function to consume the agent output and format it into our report:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {
        "id": "xZxjrfBfjFPl"
      },
      "outputs": [],
      "source": [
        "def build_report(output: dict):\n",
        "    research_steps = output[\"research_steps\"]\n",
        "    if type(research_steps) is list:\n",
        "        research_steps = \"\\n\".join([f\"- {r}\" for r in research_steps])\n",
        "    sources = output[\"sources\"]\n",
        "    if type(sources) is list:\n",
        "        sources = \"\\n\".join([f\"- {s}\" for s in sources])\n",
        "    return f\"\"\"\n",
        "INTRODUCTION\n",
        "------------\n",
        "{output[\"introduction\"]}\n",
        "\n",
        "RESEARCH STEPS\n",
        "--------------\n",
        "{research_steps}\n",
        "\n",
        "REPORT\n",
        "------\n",
        "{output[\"main_body\"]}\n",
        "\n",
        "CONCLUSION\n",
        "----------\n",
        "{output[\"conclusion\"]}\n",
        "\n",
        "SOURCES\n",
        "-------\n",
        "{sources}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjbPRhk8dhfs",
        "outputId": "5bd2070c-1f84-447a-c209-a9854e5af3b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "INTRODUCTION\n",
            "------------\n",
            "The name Dreyfus is associated with a significant figure in family history.\n",
            "\n",
            "RESEARCH STEPS\n",
            "--------------\n",
            "I conducted a search for information on Dreyfus and found relevant details about Jacques Dreyfus, an ancestor in the family lineage.\n",
            "\n",
            "REPORT\n",
            "------\n",
            "Jacques Dreyfus was born on January 9, 1829, and married Catherine Lévy in 1860. He was a cloth peddler who played an important role in the family by traveling to supply retailers in underserved towns. His father was Isaac Dreyfus, often referred to as Louis, who was born in 1766 and married Rachel Gugenheim. The Dreyfus family has a rich history with several notable members.\n",
            "\n",
            "CONCLUSION\n",
            "----------\n",
            "Jacques Dreyfus's contributions to the family and his role as a peddler highlight the family's entrepreneurial spirit during that era.\n",
            "\n",
            "SOURCES\n",
            "-------\n",
            "- rag_search\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(build_report(\n",
        "    output=out[\"intermediate_steps\"][-1].tool_input\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBgBR3PdiXIg"
      },
      "source": [
        "Now let's try with an on-topic question on AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a21f9VneePw_",
        "outputId": "49ebe6a1-16e0-46fb-f0a5-7fae3e2c1f3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "run_oracle\n",
            "intermediate_steps: []\n",
            "rag_search_filter.invoke(input={'query': 'La Belle au bois dormant', 'author': 'family'})\n",
            "run_oracle\n",
            "intermediate_steps: [AgentAction(tool='rag_search_filter', tool_input={'query': 'La Belle au bois dormant', 'author': 'family'}, log='TBD'), AgentAction(tool='rag_search_filter', tool_input={'query': 'La Belle au bois dormant', 'author': 'family'}, log='')]\n",
            "rag_search_filter.invoke(input={'query': 'La Belle au bois dormant', 'author': 'family'})\n",
            "run_oracle\n",
            "intermediate_steps: [AgentAction(tool='rag_search_filter', tool_input={'query': 'La Belle au bois dormant', 'author': 'family'}, log='TBD'), AgentAction(tool='rag_search_filter', tool_input={'query': 'La Belle au bois dormant', 'author': 'family'}, log=''), AgentAction(tool='rag_search_filter', tool_input={'query': 'La Belle au bois dormant', 'author': 'family'}, log='TBD'), AgentAction(tool='rag_search_filter', tool_input={'query': 'La Belle au bois dormant', 'author': 'family'}, log='')]\n",
            "rag_search_filter.invoke(input={'query': 'La Belle au bois dormant', 'author': 'family'})\n",
            "run_oracle\n",
            "intermediate_steps: [AgentAction(tool='rag_search_filter', tool_input={'query': 'La Belle au bois dormant', 'author': 'family'}, log='TBD'), AgentAction(tool='rag_search_filter', tool_input={'query': 'La Belle au bois dormant', 'author': 'family'}, log=''), AgentAction(tool='rag_search_filter', tool_input={'query': 'La Belle au bois dormant', 'author': 'family'}, log='TBD'), AgentAction(tool='rag_search_filter', tool_input={'query': 'La Belle au bois dormant', 'author': 'family'}, log=''), AgentAction(tool='rag_search_filter', tool_input={'query': 'La Belle au bois dormant', 'author': 'family'}, log='TBD'), AgentAction(tool='rag_search_filter', tool_input={'query': 'La Belle au bois dormant', 'author': 'family'}, log='')]\n",
            "final_answer.invoke(input={'introduction': \"The query regarding 'La Belle au bois dormant' has been explored.\", 'research_steps': \"I searched the family database for any information related to 'La Belle au bois dormant' but found no relevant entries.\", 'main_body': \"Unfortunately, there is no information available in the family database regarding 'La Belle au bois dormant.'\", 'conclusion': 'If you have any specific aspects or details you would like to know about, please let me know, and I can assist further.', 'sources': None})\n"
          ]
        }
      ],
      "source": [
        "out = runnable.invoke({\n",
        "    \"input\": \"Do we have info about La Belle au bois dormant in the family database?\",\n",
        "    \"chat_history\": []\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {
        "id": "Vis78CFR3puz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "INTRODUCTION\n",
            "------------\n",
            "The query regarding 'La Belle au bois dormant' has been explored.\n",
            "\n",
            "RESEARCH STEPS\n",
            "--------------\n",
            "I searched the family database for any information related to 'La Belle au bois dormant' but found no relevant entries.\n",
            "\n",
            "REPORT\n",
            "------\n",
            "Unfortunately, there is no information available in the family database regarding 'La Belle au bois dormant.'\n",
            "\n",
            "CONCLUSION\n",
            "----------\n",
            "If you have any specific aspects or details you would like to know about, please let me know, and I can assist further.\n",
            "\n",
            "SOURCES\n",
            "-------\n",
            "None\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(build_report(\n",
        "    output=out[\"intermediate_steps\"][-1].tool_input\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNyxZL4SNjhX"
      },
      "source": [
        "Let's ask about RAG specifically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {
        "id": "x0VmnWlWE6Lg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "run_oracle\n",
            "intermediate_steps: []\n",
            "rag_search.invoke(input={'query': 'Dreyfus history'})\n",
            "run_oracle\n",
            "intermediate_steps: [AgentAction(tool='rag_search', tool_input={'query': 'Dreyfus history'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'Dreyfus history'}, log='Doc name: Pdf img\\nAuthor: John Doe\\nSummary: Isaac, souvent appelé Louis, est l\\'ancêtre direct né en 1766 à Froeningen, marié à Rachel Gugenheim (1772-1843). Ils ont eu six enfants, dont Lehmann (Clément), né en 1800, qui a épousé Athelle Bloch en 1827. Ils ont eu neuf enfants, parmi lesquels Jacques Dreyfus, né le 9 janvier 1829, qui a épousé Catherine Lévy en 1860 et est décédé en 1893. Jacques, colporteur de tissus, a joué un rôle significatif dans la famille, voyageant pour approvisionner des revendeurs dans des bourgs non desservis.\\nChunks: 118.0\\n\\n---\\nDoc name: La belle au bois dormant\\nAuthor: Perrault\\nSummary: In \"La Belle au Bois Dormant,\" a princess pricks her finger on a spindle, falling into a deep sleep as foretold by the fairies. Despite efforts to revive her, she remains unconscious. The king places her in a beautifully adorned chamber, where she appears angelic, still breathing but unresponsive. He decides to let her sleep until the time of her awakening. Meanwhile, a good fairy, who had previously saved her life by cursing her to sleep for a hundred years, learns of the incident through a dwarf with magical boots.\\nChunks: 3.0\\n')]\n",
            "final_answer.invoke(input={'introduction': 'The Dreyfus family has a notable history, particularly through its ancestor Jacques Dreyfus.', 'research_steps': \"I found information about the Dreyfus family lineage, starting with Isaac, often called Louis, who was born in 1766. He married Rachel Gugenheim and had six children. One of his descendants, Jacques Dreyfus, born in 1829, played a significant role in the family's history.\", 'main_body': \"Jacques Dreyfus married Catherine Lévy in 1860 and passed away in 1893. He was a traveling fabric merchant, which was significant for the family's economic activities, as he supplied goods to retailers in underserved areas. This aspect of his life highlights the family's involvement in trade and commerce during that period.\", 'conclusion': \"The Dreyfus family's history reflects a lineage of merchants and their contributions to local economies through trade.\", 'sources': \"{'query': 'Dreyfus history', 'author': 'John Doe'}\"})\n"
          ]
        }
      ],
      "source": [
        "out = runnable.invoke({\n",
        "    \"input\": \"What's the history of the Dreyfus?\",\n",
        "    \"chat_history\": []\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {
        "id": "I7LssyU4Nqis"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "INTRODUCTION\n",
            "------------\n",
            "The Dreyfus family has a notable history, particularly through its ancestor Jacques Dreyfus.\n",
            "\n",
            "RESEARCH STEPS\n",
            "--------------\n",
            "I found information about the Dreyfus family lineage, starting with Isaac, often called Louis, who was born in 1766. He married Rachel Gugenheim and had six children. One of his descendants, Jacques Dreyfus, born in 1829, played a significant role in the family's history.\n",
            "\n",
            "REPORT\n",
            "------\n",
            "Jacques Dreyfus married Catherine Lévy in 1860 and passed away in 1893. He was a traveling fabric merchant, which was significant for the family's economic activities, as he supplied goods to retailers in underserved areas. This aspect of his life highlights the family's involvement in trade and commerce during that period.\n",
            "\n",
            "CONCLUSION\n",
            "----------\n",
            "The Dreyfus family's history reflects a lineage of merchants and their contributions to local economies through trade.\n",
            "\n",
            "SOURCES\n",
            "-------\n",
            "{'query': 'Dreyfus history', 'author': 'John Doe'}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(build_report(\n",
        "    output=out[\"intermediate_steps\"][-1].tool_input\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rp2uaRW7cAoM"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
