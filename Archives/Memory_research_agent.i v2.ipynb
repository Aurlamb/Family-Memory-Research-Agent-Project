{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyvWVMBTDX2M"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pinecone-io/examples/blob/master/learn/generation/langchain/langgraph/01-gpt-4o-research-agent.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/pinecone-io/examples/blob/master/learn/generation/langchain/langgraph/01-gpt-4o-research-agent.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PFp0JhOWCU5"
      },
      "source": [
        "# GPT-4o Research Agent in LangGraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "to run with Python 3.12.7 else, incompatibilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TCVLlfNyAtxD",
        "outputId": "a281097c-e50a-4106-e997-58ff87314ea5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'apt-get' n'est pas reconnu en tant que commande interne\n",
            "ou externe, un programme ex�cutable ou un fichier de commandes.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install graphviz libgraphviz-dev pkg-config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbR8rt-EtqWh"
      },
      "source": [
        "Now we install Python libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "FUt2EoJZu6M3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × Building wheel for pygraphviz (pyproject.toml) did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [51 lines of output]\n",
            "      running bdist_wheel\n",
            "      running build\n",
            "      running build_py\n",
            "      creating build\\lib.win-amd64-cpython-312\\pygraphviz\n",
            "      copying pygraphviz\\agraph.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\n",
            "      copying pygraphviz\\graphviz.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\n",
            "      copying pygraphviz\\scraper.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\n",
            "      copying pygraphviz\\testing.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\n",
            "      copying pygraphviz\\__init__.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\n",
            "      creating build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_attribute_defaults.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_clear.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_close.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_drawing.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_edge_attributes.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_graph.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_html.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_layout.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_node_attributes.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_readwrite.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_repr_mimebundle.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_scraper.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_string.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_subgraph.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\test_unicode.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      copying pygraphviz\\tests\\__init__.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
            "      running egg_info\n",
            "      writing pygraphviz.egg-info\\PKG-INFO\n",
            "      writing dependency_links to pygraphviz.egg-info\\dependency_links.txt\n",
            "      writing top-level names to pygraphviz.egg-info\\top_level.txt\n",
            "      reading manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n",
            "      reading manifest template 'MANIFEST.in'\n",
            "      warning: no files found matching '*.png' under directory 'doc'\n",
            "      warning: no files found matching '*.html' under directory 'doc'\n",
            "      warning: no files found matching '*.txt' under directory 'doc'\n",
            "      warning: no files found matching '*.css' under directory 'doc'\n",
            "      warning: no previously-included files matching '*~' found anywhere in distribution\n",
            "      warning: no previously-included files matching '*.pyc' found anywhere in distribution\n",
            "      warning: no previously-included files matching '.svn' found anywhere in distribution\n",
            "      no previously-included directories found matching 'doc\\build'\n",
            "      adding license file 'LICENSE'\n",
            "      writing manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n",
            "      copying pygraphviz\\graphviz.i -> build\\lib.win-amd64-cpython-312\\pygraphviz\n",
            "      copying pygraphviz\\graphviz_wrap.c -> build\\lib.win-amd64-cpython-312\\pygraphviz\n",
            "      running build_ext\n",
            "      building 'pygraphviz._graphviz' extension\n",
            "      creating build\\temp.win-amd64-cpython-312\\Release\\pygraphviz\n",
            "      \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.42.34433\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -DSWIG_PYTHON_STRICT_BYTE_CHAR -DGVDLL -Ic:\\ProgramData\\anaconda3\\include -Ic:\\ProgramData\\anaconda3\\Include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.42.34433\\include\" \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Auxiliary\\VS\\include\" /Tcpygraphviz/graphviz_wrap.c /Fobuild\\temp.win-amd64-cpython-312\\Release\\pygraphviz\\graphviz_wrap.obj\n",
            "      graphviz_wrap.c\n",
            "      c:\\ProgramData\\anaconda3\\include\\pyconfig.h(59): fatal error C1083: Impossible d'ouvrir le fichier includeÿ: 'io.h'ÿ: No such file or directory\n",
            "      error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2022\\\\BuildTools\\\\VC\\\\Tools\\\\MSVC\\\\14.42.34433\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  ERROR: Failed building wheel for pygraphviz\n",
            "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pygraphviz)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: semantic-router in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (0.0.72)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.5 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from semantic-router) (3.10.11)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from semantic-router) (0.4.6)\n",
            "Requirement already satisfied: colorlog<7.0.0,>=6.8.0 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from semantic-router) (6.9.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.25.2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from semantic-router) (1.26.4)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from semantic-router) (1.60.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.3 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from semantic-router) (2.10.5)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.1 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from semantic-router) (6.0.2)\n",
            "Requirement already satisfied: regex>=2023.12.25 in c:\\programdata\\anaconda3\\lib\\site-packages (from semantic-router) (2024.9.11)\n",
            "Requirement already satisfied: requests-mock<2.0.0,>=1.12.1 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from semantic-router) (1.12.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.6.0 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from semantic-router) (0.8.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.9.5->semantic-router) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.9.5->semantic-router) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.9.5->semantic-router) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.9.5->semantic-router) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.9.5->semantic-router) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.9.5->semantic-router) (1.18.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->semantic-router) (4.2.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->semantic-router) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->semantic-router) (0.27.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from openai<2.0.0,>=1.10.0->semantic-router) (0.8.2)\n",
            "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->semantic-router) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from openai<2.0.0,>=1.10.0->semantic-router) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from openai<2.0.0,>=1.10.0->semantic-router) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.3->semantic-router) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3.0.0,>=2.5.3->semantic-router) (2.27.2)\n",
            "Requirement already satisfied: requests<3,>=2.22 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from requests-mock<2.0.0,>=1.12.1->semantic-router) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->semantic-router) (3.10)\n",
            "Requirement already satisfied: certifi in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->semantic-router) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->semantic-router) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\programdata\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->semantic-router) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.22->requests-mock<2.0.0,>=1.12.1->semantic-router) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.22->requests-mock<2.0.0,>=1.12.1->semantic-router) (2.3.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.9.5->semantic-router) (0.2.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: cohere in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (5.13.11)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from cohere) (1.10.0)\n",
            "Requirement already satisfied: httpx>=0.21.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from cohere) (0.27.0)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from cohere) (0.4.0)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from cohere) (2.10.5)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from cohere) (2.27.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from cohere) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from cohere) (0.20.3)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from cohere) (2.32.0.20241016)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from cohere) (4.12.2)\n",
            "Requirement already satisfied: anyio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.21.2->cohere) (4.2.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from httpx>=0.21.2->cohere) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.21.2->cohere) (1.0.2)\n",
            "Requirement already satisfied: idna in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from httpx>=0.21.2->cohere) (3.10)\n",
            "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.21.2->cohere) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\programdata\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic>=1.9.2->cohere) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.0.0->cohere) (2.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from tokenizers<1,>=0.15->cohere) (0.27.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2024.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.67.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: langchain_core in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (0.3.32)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langchain_core) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langchain_core) (0.3.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langchain_core) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langchain_core) (2.10.5)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain_core) (8.2.3)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langchain_core) (4.12.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (2.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_core) (0.27.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<0.4,>=0.1.125->langchain_core) (3.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<0.4,>=0.1.125->langchain_core) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_core) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_core) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain_core) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain_core) (2.27.2)\n",
            "Requirement already satisfied: anyio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (4.2.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (1.0.2)\n",
            "Requirement already satisfied: idna in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (3.10)\n",
            "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\programdata\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain_core) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain_core) (2.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Installing required Python libraries\n",
        "%pip install -qU \\\n",
        "    langchain-pinecone==0.1.1 \\\n",
        "    langchain-openai==0.1.9 \\\n",
        "    langchain==0.2.5 \\\n",
        "    langchain-core==0.2.9 \\\n",
        "    langgraph \\\n",
        "    semantic-router==0.0.48 \\\n",
        "    serpapi==0.1.5 \\\n",
        "    google-search-results==2.4.2 \\\n",
        "    pygraphviz==1.12\n",
        "%pip install --upgrade semantic-router\n",
        "%pip install --upgrade cohere\n",
        "# %pip install -U langsmith\n",
        "%pip install langchain_core"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "from pathlib import Path\n",
        "\n",
        "# Load path from the environment variable\n",
        "env_ih1 = os.getenv(\"ENV_IH1\")\n",
        "\n",
        "dotenv_path = Path(env_ih1)\n",
        "load_dotenv(dotenv_path=dotenv_path)\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "PINECONE_API_KEY= os.getenv('PINECONE_KEY')\n",
        "SERPAPI_API_KEY = os.getenv('SERPAPI_API_KEY')\n",
        "STEAMSHIP_API_KEY = os.getenv('STEAMSHIP_API_KEY')\n",
        "LANGSMITH_API_KEY = os.getenv('LANGSMITH_API_KEY')\n",
        "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
        "GEMINI_KEY = os.getenv('GEMINI_KEY')\n",
        "\n",
        "os.environ['PATH'] += os.pathsep + '/usr/bin'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NMwEHwM9G1Sc"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from langsmith import wrappers, traceable\n",
        "\n",
        "LANGSMITH_API_KEY= LANGSMITH_API_KEY\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"]=\"memory-project\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohBxmFyTBFT0"
      },
      "source": [
        "### Connect to Pinecone DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LjsIFVbtKBu4"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "from semantic_router.encoders import OpenAIEncoder\n",
        "\n",
        "# os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or getpass(\"OpenAI API key: \")\n",
        "\n",
        "# from dotenv import load_dotenv, find_dotenv\n",
        "import os\n",
        "# _ = load_dotenv(find_dotenv())\n",
        "\n",
        "OPENAI_API_KEY = OPENAI_API_KEY\n",
        "PINECONE_API_KEY = PINECONE_API_KEY\n",
        "\n",
        "encoder = OpenAIEncoder(\n",
        "    name=\"text-embedding-3-small\",\n",
        "    openai_api_key=OPENAI_API_KEY \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DIbY89BwOH_x"
      },
      "outputs": [],
      "source": [
        "from pinecone import Pinecone\n",
        "# Initialize Pinecone\n",
        "pinecone = Pinecone(\n",
        "    api_key=PINECONE_API_KEY,  # Replace with your Pinecone API key\n",
        "    environment=\"us-east-1\"  # Replace with your Pinecone environment (e.g., \"us-west1-gcp\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "J233t2I4HmjD"
      },
      "outputs": [],
      "source": [
        "from pinecone import Pinecone\n",
        "\n",
        "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
        "# PINECONE_API_KEY = userdata.get(\"PINECONE_KEY\") or \"YOUR_API_KEY\"\n",
        "\n",
        "# configure client\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-GHzWs3KlJn",
        "outputId": "80e84756-92d7-4915-a173-1508daf1cc3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {'': {'vector_count': 1154}},\n",
              " 'total_vector_count': 1154}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Connect to the existing index\n",
        "index_name = \"memory-project\"  # Replace with your existing index name\n",
        "# connect to index\n",
        "index = pc.Index(index_name)\n",
        "time.sleep(1)\n",
        "# view index stats\n",
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "actWflaEKgVb"
      },
      "outputs": [],
      "source": [
        "# from pinecone import ServerlessSpec\n",
        "\n",
        "# spec = ServerlessSpec(\n",
        "#     cloud=\"aws\", region=\"us-west-2\"  # us-east-1\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWijfk8LKil7",
        "outputId": "8be19a4b-37e3-4b4c-ab2c-6837da316ad6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1536"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dims = len(encoder([\"some random text\"])[0])\n",
        "dims"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hITmdwQ7Qns0"
      },
      "source": [
        "## Graph State\n",
        "\n",
        "We will define a custom graph state to support our agent-oriented decision making."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "x7Fj9KNjQvUq"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict, Annotated, List, Union\n",
        "from langchain_core.agents import AgentAction, AgentFinish\n",
        "from langchain_core.messages import BaseMessage\n",
        "import operator\n",
        "\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    input: str\n",
        "    chat_history: list[BaseMessage]\n",
        "    intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp4uQFBKQdyI"
      },
      "source": [
        "There are four parts to our agent state, those are:\n",
        "\n",
        "* `input`: this is the user's most recent query, usually this would be a question that we want to answer with our research agent.\n",
        "* `chat_history`: we are building a conversational agent that can support multiple interactions, to allow previous interactions to provide additional context throughout our agent logic we include the chat history in the agent state.\n",
        "* `intermediate_steps`: provides a record of all steps the research agent will take between the user asking a question via `input` and the agent providing a final answer. This can include things like \"search arxiv\", \"perform general purpose web search\", etc. These intermediate steps are crucial to allowing the agent to follow a path of coherent actions and ultimately producing an informed final answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlVbgX39Rhxj"
      },
      "source": [
        "## Custom Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jpYR2DYsHtgb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: langchain_core in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (0.3.32)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langchain_core) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langchain_core) (0.3.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langchain_core) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langchain_core) (2.10.5)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain_core) (8.2.3)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langchain_core) (4.12.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (2.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_core) (0.27.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<0.4,>=0.1.125->langchain_core) (3.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<0.4,>=0.1.125->langchain_core) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_core) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_core) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain_core) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain_core) (2.27.2)\n",
            "Requirement already satisfied: anyio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (4.2.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (1.0.2)\n",
            "Requirement already satisfied: idna in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (3.10)\n",
            "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\programdata\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain_core) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain_core) (2.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install langchain_core\n",
        "from langchain_core.tools import tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uydhqzKIU2F"
      },
      "source": [
        "Let's test the tool."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLX1N7oWKiNZ"
      },
      "source": [
        "### Web Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsOutTz9KjoL"
      },
      "source": [
        "The web search tool will provide the agent with access to web search. It will be instructed to use this for more general knowledge queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vuv_exwsH8ZJ"
      },
      "outputs": [],
      "source": [
        "from serpapi import GoogleSearch\n",
        "\n",
        "serpapi_params = {\n",
        "    \"engine\": \"google\",\n",
        "    \"api_key\": SERPAPI_API_KEY\n",
        "}\n",
        "\n",
        "search = GoogleSearch({\n",
        "    **serpapi_params,\n",
        "    \"q\": \"query\"\n",
        "})\n",
        "\n",
        "results = search.get_dict()[\"organic_results\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KklJP-XSTqLG"
      },
      "outputs": [],
      "source": [
        "contexts = \"\\n---\\n\".join(\n",
        "    [\"\\n\".join([x[\"title\"], x[\"snippet\"], x[\"link\"]]) for x in results]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_b083gU3T-8K",
        "outputId": "3535f58b-8c83-429d-a3dc-f588aa2442ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query Definition & Meaning\n",
            "ask, question, interrogate, query, inquire mean to address a person in order to gain information. ask implies no more than the putting of a ...\n",
            "https://www.merriam-webster.com/dictionary/query\n",
            "---\n",
            "QUERY | definition in the Cambridge English Dictionary\n",
            "to ask questions, especially in order to check if something is true or correct: A few students have queried their grades.\n",
            "https://dictionary.cambridge.org/us/dictionary/english/query\n",
            "---\n",
            "Query\n",
            "Computing and technology · Query, a precise request for information retrieval made to a database, data structure or information system · Command-query ...\n",
            "https://en.wikipedia.org/wiki/Query\n",
            "---\n",
            "What is a query? | Definition from TechTarget\n",
            "In a database context, a query is a request for information or data made by a user and written in a specific format. The format is determined by the query ...\n",
            "https://www.techtarget.com/searchdatamanagement/definition/query\n",
            "---\n",
            "QUERY Synonyms: 118 Similar and Opposite Words\n",
            "Synonyms for QUERY: doubt, skepticism, suspicion, uncertainty, concern, reservation, disbelief, distrust; Antonyms of QUERY: belief, conviction, trust, ...\n",
            "https://www.merriam-webster.com/thesaurus/query\n",
            "---\n",
            "QUERY function - Google Docs Editors Help\n",
            "QUERY function runs a Google Visualization API Query Language query across data. Sample Usage: QUERY(A2:E6,\"select avg(A) pivot B\")\n",
            "https://support.google.com/docs/answer/3093343?hl=en\n",
            "---\n",
            "QUERY Definition & Meaning\n",
            "verb (used with object). queried, querying. to ask or inquire about: No one queried his presence. to question as doubtful or obscure: to query a statement.\n",
            "https://www.dictionary.com/browse/query\n",
            "---\n",
            "Query - Definition, Meaning & Synonyms\n",
            "A query is a question, or the search for a piece of information. The Latin root quaere means \"to ask\" and it's the basis of ...\n",
            "https://www.vocabulary.com/dictionary/query\n",
            "---\n",
            "QUERY definition in American English\n",
            "1. a question; inquiry 2. a doubt 3. a question mark (?) placed after a question or used to question the accuracy of written or printed matter.\n",
            "https://www.collinsdictionary.com/us/dictionary/english/query\n",
            "---\n",
            "Home - Query\n",
            "Query is a federated search platform for security data providing expanded data visibility without centralization.\n",
            "https://www.query.ai/\n"
          ]
        }
      ],
      "source": [
        "print(contexts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtmOt4nQH4KS"
      },
      "source": [
        "We put this process into a tool:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TYmOL54xH6GH"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool(\"web_search\")\n",
        "def web_search(query: str):\n",
        "    \"\"\"Finds general knowledge information using Google search. Can also be used\n",
        "    to augment more 'general' knowledge to a previous specialist query.\"\"\"\n",
        "    search = GoogleSearch({\n",
        "        **serpapi_params,\n",
        "        \"q\": query,\n",
        "        \"num\": 5\n",
        "    })\n",
        "    results = search.get_dict()[\"organic_results\"]\n",
        "    contexts = \"\\n---\\n\".join(\n",
        "        [\"\\n\".join([x[\"title\"], x[\"snippet\"], x[\"link\"]]) for x in results]\n",
        "    )\n",
        "    return contexts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCBZjWfAIN0N"
      },
      "source": [
        "### RAG Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY37AFP6RBOP"
      },
      "source": [
        "We provide two RAG-focused tools for our agent. The `rag_search` allows the agent to perform a simple RAG search for some information across _all_ indexed research papers. The `rag_search_filter` also searches, but _within_ a specific paper which is filtered for via the `arxiv_id` parameter.\n",
        "\n",
        "We also define the `format_rag_contexts` function to handle the transformation of our Pinecone results from a JSON object to a readble plaintext format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "SPcrbQfdRrda"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "\n",
        "def format_rag_contexts(matches: list):\n",
        "    contexts = []\n",
        "    for x in matches:\n",
        "        text = (\n",
        "            f\"Doc name: {x['metadata']['Doc name']}\\n\"\n",
        "            f\"Author: {x['metadata']['Author']}\\n\"\n",
        "            f\"Summary: {x['metadata']['Summary']}\\n\"\n",
        "            f\"Chunk_ID: {x['metadata']['Chunk_ID']}\\n\"\n",
        "            # f\"Text: {x['metadata']['Text']}\"\n",
        "        )\n",
        "        contexts.append(text)\n",
        "    context_str = \"\\n---\\n\".join(contexts)\n",
        "    return context_str\n",
        "\n",
        "\n",
        "\n",
        "@tool(\"rag_search\")\n",
        "def rag_search(query: str):\n",
        "    \"\"\"Finds related information using a natural language query in the family history.\"\"\"\n",
        "    xq = encoder([query])\n",
        "    xc = index.query(vector=xq, top_k=3, include_metadata=True)\n",
        "    context_str = format_rag_contexts(xc[\"matches\"])\n",
        "    return context_str\n",
        "\n",
        "@tool(\"rag_search_filter\")\n",
        "def rag_search_filter(query: str, author: str):\n",
        "    \"\"\"Finds related information using a natural language query in the family history given an author.\"\"\"\n",
        "    xq = encoder([query])\n",
        "    xc = index.query(vector=xq, top_k=6, include_metadata=True, filter={\"Author\": author})\n",
        "    context_str = format_rag_contexts(xc[\"matches\"])\n",
        "    return context_str\n",
        "\n",
        "\n",
        "@tool(\"rag_search_similarity\")\n",
        "def rag_search_similarity(query: str):\n",
        "    \"\"\"Finds info in Pinecone DB using sparse-dense hybrid search.\"\"\"\n",
        "    \n",
        "    xq_dense = encoder([query])  # Convert query to dense vector\n",
        "    xq_sparse = bm25_encoder(query)  # Convert query to sparse BM25 vector\n",
        "    \n",
        "    xc = index.query(\n",
        "        vector=xq_dense,  # Dense semantic representation\n",
        "        sparse_vector=xq_sparse,  # Sparse keyword-based representation\n",
        "        top_k=6,\n",
        "        include_metadata=True  # No metadata filtering\n",
        "    )\n",
        "    \n",
        "    context_str = format_rag_contexts(xc[\"matches\"])\n",
        "    return context_str\n",
        "\n",
        "\n",
        "\n",
        "# @tool(\"enriched_rag_search\")\n",
        "# def rag_search(query: str):\n",
        "#     \"\"\"Finds specialist information on AI using a natural language query.\"\"\"\n",
        "#     xq = encoder([query])\n",
        "#     xc = index.query(vector=xq, top_k=2, include_metadata=True)\n",
        "#     context_str = format_rag_contexts(xc[\"matches\"])\n",
        "#     return context_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# retriever = vectorstore.as_retriever(k=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "W36mGme-f7Jb",
        "outputId": "b350afc1-2088-4c99-f1c9-68c21f707ec7"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'text'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrag_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1963\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\tools\\base.py:725\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[0;32m    723\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[0;32m    724\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_error(error_to_raise)\n\u001b[1;32m--> 725\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[0;32m    726\u001b[0m output \u001b[38;5;241m=\u001b[39m _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, status)\n\u001b[0;32m    727\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_tool_end(output, color\u001b[38;5;241m=\u001b[39mcolor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\tools\\base.py:694\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_param \u001b[38;5;241m:=\u001b[39m _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run):\n\u001b[0;32m    693\u001b[0m     tool_kwargs \u001b[38;5;241m=\u001b[39m tool_kwargs \u001b[38;5;241m|\u001b[39m {config_param: config}\n\u001b[1;32m--> 694\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent_and_artifact\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    696\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\tools\\structured.py:80\u001b[0m, in \u001b[0;36mStructuredTool._run\u001b[1;34m(self, config, run_manager, *args, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config_param \u001b[38;5;241m:=\u001b[39m _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc):\n\u001b[0;32m     79\u001b[0m         kwargs[config_param] \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStructuredTool does not support sync invocation.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
            "Cell \u001b[1;32mIn[28], line 25\u001b[0m, in \u001b[0;36mrag_search\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m     23\u001b[0m xq \u001b[38;5;241m=\u001b[39m encoder([query])\n\u001b[0;32m     24\u001b[0m xc \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mquery(vector\u001b[38;5;241m=\u001b[39mxq, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, include_metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 25\u001b[0m context_str \u001b[38;5;241m=\u001b[39m \u001b[43mformat_rag_contexts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmatches\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m context_str\n",
            "Cell \u001b[1;32mIn[28], line 10\u001b[0m, in \u001b[0;36mformat_rag_contexts\u001b[1;34m(matches)\u001b[0m\n\u001b[0;32m      5\u001b[0m contexts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m matches:\n\u001b[0;32m      7\u001b[0m     text \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDoc name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthor: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAuthor\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 10\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummary: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChunk_ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChunk_ID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;66;03m# f\"Text: {x['metadata']['Text']}\"\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     )\n\u001b[0;32m     14\u001b[0m     contexts\u001b[38;5;241m.\u001b[39mappend(text)\n\u001b[0;32m     15\u001b[0m context_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(contexts)\n",
            "\u001b[1;31mKeyError\u001b[0m: 'text'"
          ]
        }
      ],
      "source": [
        "rag_search.run(\"1963\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDBmpJ0URzKS"
      },
      "source": [
        "### Final Answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWVKYuQ6R6nB"
      },
      "source": [
        "Finally, we define a \"final answer\" tool. This isn't a tool in the usual sense, instead we use it to force a particular output format from our LLM via the function/tool calling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.messages import SystemMessage, AIMessage\n",
        "\n",
        "@tool(\"report\")\n",
        "def report(\n",
        "    introduction: str,\n",
        "    research_steps: str,\n",
        "    main_body: str,\n",
        "    conclusion: str,\n",
        "    sources: Union[str, List[str], None] = None\n",
        "):\n",
        "    \"\"\"\n",
        "    You are the family safe, keeper of the family collective memory.\n",
        "\n",
        "    Returns a natural language response to the user's question based on the family memory database.\n",
        "\n",
        "    Do not invent anything but you are allowed to link information together from multiple sources.\n",
        "\n",
        "    If you can't find an answer with sources from {\"tool\": \"rag_search\"}, just say that you don't know.\n",
        "    \"\"\"\n",
        "\n",
        "    # Format the research steps and sources\n",
        "    if isinstance(research_steps, list):\n",
        "        research_steps = \"\\n\".join([f\"- {r}\" for r in research_steps])\n",
        "    if isinstance(sources, list):\n",
        "        sources = \"\\n\".join([f\"- {s}\" for s in sources])\n",
        "\n",
        "    # System prompt to guide the final response\n",
        "    system_prompt = SystemMessage(\n",
        "        content=(\n",
        "            \"You are the family safe, the guardian of collective memory. \"\n",
        "            \"Provide a detailed but concise summary based on the following sections: \"\n",
        "            \"introduction, research steps, main body, and conclusion. \"\n",
        "            \"Include sources if available and only use verified information.\"\n",
        "            \"If you can't find an answer with sources from {'tool': 'rag_search'}, just say that you don't know.\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Combine the sections into a message\n",
        "    user_query_context = (\n",
        "        f\"### Introduction:\\n{introduction}\\n\\n\"\n",
        "        f\"### Research Steps:\\n{research_steps}\\n\\n\"\n",
        "        f\"### Main Body:\\n{main_body}\\n\\n\"\n",
        "        f\"### Conclusion:\\n{conclusion}\\n\\n\"\n",
        "        f\"### Sources:\\n{sources if sources else 'No sources available.'}\"\n",
        "    )\n",
        "\n",
        "    # Append the system prompt to messages and call the LLM\n",
        "    messages = [system_prompt, AIMessage(content=user_query_context)]\n",
        "    final_response = llm.invoke(messages)  # Call the LLM for a response\n",
        "\n",
        "    return final_response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.messages import SystemMessage, AIMessage\n",
        "\n",
        "@tool(\"final_answer\")\n",
        "def final_answer(\n",
        "    answer: str,\n",
        "    explore_next: str,\n",
        "    sources: Union[str, List[str], None] = None\n",
        "):\n",
        "    \"\"\"\n",
        "    You are the family safe, keeper of the family collective memory.\n",
        "\n",
        "    Returns a natural language response to the user's question based on the family memory database.\n",
        "\n",
        "    Do not invent anything but you are allowed to link information together from multiple sources.\n",
        "\n",
        "    If you can't find an answer with sources from {\"tool\": \"rag_search\"}, just say that you don't know.\n",
        "    \"\"\"\n",
        "\n",
        "    # Format the research steps and sources\n",
        "    if isinstance(sources, list):\n",
        "        sources = \"\\n\".join([f\"- {s}\" for s in sources])\n",
        "\n",
        "    # System prompt to guide the final response\n",
        "    system_prompt = SystemMessage(\n",
        "        content=(\n",
        "            \"You are the family safe, the guardian of collective memory. \"\n",
        "            \"Provide a detailed but concise answer to the original query.\"\n",
        "            \"If a report is requested, use {'tool': 'report'} to find more information.\"\n",
        "            \"Include sources if available and only use verified information.\"\n",
        "            \"If you can't find an answer with sources from {'tool': 'rag_search'}, just say that you don't know.\"\n",
        "            \"Offer to explore more information with the 'explore_next' prompt.\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Combine the sections into a message\n",
        "    user_query_context = (\n",
        "        f\"### answer:\\n{answer}\\n\\n\"\n",
        "        f\"### Sources:\\n{sources if sources else 'No sources available.'}\"\n",
        "        f\"### Explore Next:\\n{explore_next}\"\n",
        "\n",
        "    )\n",
        "\n",
        "    # Append the system prompt to messages and call the LLM\n",
        "    messages = [system_prompt, AIMessage(content=user_query_context)]\n",
        "    final_response = llm.invoke(messages)  # Call the LLM for a response\n",
        "\n",
        "    return final_response\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8OsQ3tIS-_t"
      },
      "source": [
        "## Initialize the \"Oracle\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YykLRD5rXfr5"
      },
      "source": [
        "The **Oracle** LLM is our graph's decision maker. It decides which path we should take down our graph. It functions similarly to an agent but is much simpler and reliable.\n",
        "\n",
        "The Oracle consists of an LLM provided with a set of potential function calls (ie our tools) that it can decide to use — we force it to use _at least_ one of those tool using the `tool_choice=\"any\"` setting (see below). Our Oracle only makes the decision to use a tool, it doesn't execute the tool code itself (we do that seperately in our graph)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRlREI1wYSd0"
      },
      "source": [
        "### Oracle Prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFE638_CYUbf"
      },
      "source": [
        "Our prompt for the Oracle will emphasize it's decision making ability within the `system_prompt`, leave a placeholder for us to later insert `chat_history`, and provide a place for us to insert the user `input`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "FBZrvHDAYmOP"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "system_prompt = \"\"\"You are the Family Safe, keeper of the family's collective memory. \n",
        "Your role is to decide how to handle user queries using the available tools.\n",
        "\n",
        "**Tool Usage:**\n",
        "- Do NOT reuse a tool for the same query (check the scratchpad).\n",
        "- Do NOT use any tool more than **twice**.\n",
        "- Prioritize **rag_search** for gathering information.\n",
        "- Use **web_search** only for additional historical context.\n",
        "\n",
        "**Response Protocol:**\n",
        "- If **rag_search** provides no answer, state that you don't know or can't any information about this topic\"\n",
        "- NEVER invent information or use data beyond the family memory.\n",
        "- Always provide sources via the **final_answer** tool.\n",
        "\n",
        "By following these rules, you ensure accurate and responsible responses.\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_prompt),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "    (\"assistant\", \"scratchpad: {scratchpad}\"),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euGh0137Ynxv"
      },
      "source": [
        "Next, we must initialize our `llm` (for this we use `gpt-4o`) and then create the _runnable_ pipeline of our Oracle.\n",
        "\n",
        "The runnable connects our inputs (the user `input` and `chat_history`) to our `prompt`, and our `prompt` to our `llm`. It is also where we _bind_ our tools to the LLM and enforce function calling via `tool_choice=\"any\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install the missing package\n",
        "# %pip install langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "0gKxRe4tTBHX"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import ToolCall, ToolMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    openai_api_key = OPENAI_API_KEY,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "tools=[\n",
        "    rag_search_filter,\n",
        "    rag_search,\n",
        "    # web_search,\n",
        "    report,\n",
        "    final_answer\n",
        "]\n",
        "\n",
        "# define a function to transform intermediate_steps from list\n",
        "# of AgentAction to scratchpad string\n",
        "def create_scratchpad(intermediate_steps: list[AgentAction]):\n",
        "    research_steps = []\n",
        "    for i, action in enumerate(intermediate_steps):\n",
        "        if action.log != \"TBD\":\n",
        "            # this was the ToolExecution\n",
        "            research_steps.append(\n",
        "                f\"Tool: {action.tool}, input: {action.tool_input}\\n\"\n",
        "                f\"Output: {action.log}\"\n",
        "            )\n",
        "    return \"\\n---\\n\".join(research_steps)\n",
        "\n",
        "oracle = (\n",
        "    {\n",
        "        \"input\": lambda x: x[\"input\"],\n",
        "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
        "        \"scratchpad\": lambda x: create_scratchpad(\n",
        "            intermediate_steps=x[\"intermediate_steps\"]\n",
        "        ),\n",
        "    }\n",
        "    | prompt\n",
        "    | llm.bind_tools(tools, tool_choice=\"any\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESCSupKbTuVR"
      },
      "source": [
        "Test the agent quickly to confirm it is functional:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5xMQ8ajTxFQ",
        "outputId": "79d202a0-561c-4d2c-9358-fd659df9a0a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_E8rfb0xUy30PAe4QidMPK5sE', 'function': {'arguments': '{\"query\":\"Dreyfus family\"}', 'name': 'rag_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 468, 'total_tokens': 487, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-cc5e7a59-cf8a-4bd4-b5e8-aec563857448-0', tool_calls=[{'name': 'rag_search', 'args': {'query': 'Dreyfus family'}, 'id': 'call_E8rfb0xUy30PAe4QidMPK5sE', 'type': 'tool_call'}], usage_metadata={'input_tokens': 468, 'output_tokens': 19, 'total_tokens': 487, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = {\n",
        "    \"input\": \"tell me something interesting about the Dreyfus family\",\n",
        "    \"chat_history\": [],\n",
        "    \"intermediate_steps\": [],\n",
        "}\n",
        "out = oracle.invoke(inputs)\n",
        "out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTwZ-7ZtZXq2"
      },
      "source": [
        "It is running but we are returning a lot of output here, we can narrow this down to what we need — ie, the chosen tool name and generated input args for the tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "u7wUMr2BUBt7",
        "outputId": "8cb7c1c4-cadf-42c2-b4fe-fde0b84cf8d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'rag_search'"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out.tool_calls[0][\"name\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "se0M1pbnaFyi",
        "outputId": "1b2bfe34-6adc-4485-c5fc-81d56bc2eae0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query': 'Dreyfus family'}"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out.tool_calls[0][\"args\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbO6IMEZaK4q"
      },
      "source": [
        "We can see now that our Oracle decided to use the `web_search` tool with a `query` of `\"interesting facts about dogs\"` — a good choice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6pAxC9kcY1F"
      },
      "source": [
        "## Define Nodes for Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8ykjVWoa0kz"
      },
      "source": [
        "We will be passing the tool use decision to our `router` which will _route_ the output to the chosen node component to run (we define these below) based on the `out.tool_calls[0][\"name\"]` value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "LcRVPIuAgcoG"
      },
      "outputs": [],
      "source": [
        "def run_oracle(state: list):\n",
        "    print(\"run_oracle\")\n",
        "    print(f\"intermediate_steps: {state['intermediate_steps']}\")\n",
        "    out = oracle.invoke(state)\n",
        "    tool_name = out.tool_calls[0][\"name\"]\n",
        "    tool_args = out.tool_calls[0][\"args\"]\n",
        "    action_out = AgentAction(\n",
        "        tool=tool_name,\n",
        "        tool_input=tool_args,\n",
        "        log=\"TBD\"\n",
        "    )\n",
        "    return {\n",
        "        \"intermediate_steps\": [action_out]\n",
        "    }\n",
        "\n",
        "def router (state: list): #Original\n",
        "    # return the tool name to use\n",
        "    if isinstance(state[\"intermediate_steps\"], list):\n",
        "        return state[\"intermediate_steps\"][-1].tool\n",
        "    else:\n",
        "        # if we output bad format go to final answer\n",
        "        print(\"Router invalid format\")\n",
        "#         return \"final_answer\"\n",
        "    \n",
        "# def router(state: list):\n",
        "#     if isinstance(state[-1].get(\"intermediate_steps\"), list):  # Access the last state entry\n",
        "#         # Return the tool name from the last intermediate step\n",
        "#         return state[-1][\"intermediate_steps\"][-1][\"tool\"]\n",
        "#     else:\n",
        "#         # Handle invalid format or empty intermediate steps\n",
        "#         print(\"Router: Invalid or missing intermediate steps. Routing to final_answer.\")\n",
        "#         return \"final_answer\"  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtBEhoDOSOCQ"
      },
      "source": [
        "All of our tools can be run using the same function logic, which we define with `run_tool`. The input parameters to our tool call and the resultant output are added to our graph state's `intermediate_steps` parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "-JGJGvDVcbvq"
      },
      "outputs": [],
      "source": [
        "tool_str_to_func = {\n",
        "    \"rag_search_filter\": rag_search_filter,\n",
        "    \"rag_search\": rag_search,\n",
        "    \"report\": report,\n",
        "    # \"fetch_arxiv\": fetch_arxiv,\n",
        "    # \"web_search\": web_search,\n",
        "    \"final_answer\": final_answer\n",
        "}\n",
        "\n",
        "def run_tool(state: list):\n",
        "    # use this as helper function so we repeat less code\n",
        "    tool_name = state[\"intermediate_steps\"][-1].tool\n",
        "    tool_args = state[\"intermediate_steps\"][-1].tool_input\n",
        "    print(f\"{tool_name}.invoke(input={tool_args})\")\n",
        "    # run tool\n",
        "    out = tool_str_to_func[tool_name].invoke(input=tool_args)\n",
        "    action_out = AgentAction(\n",
        "        tool=tool_name,\n",
        "        tool_input=tool_args,\n",
        "        log=str(out)\n",
        "    )\n",
        "    return {\"intermediate_steps\": [action_out]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwv4EsTKeZzh"
      },
      "source": [
        "## Define Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: langgraph in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (0.2.68)\n",
            "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langgraph) (0.3.32)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langgraph) (2.0.10)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langgraph) (0.1.51)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.33)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.3.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.10.5)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (8.2.3)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (4.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.27.0)\n",
            "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.12)\n",
            "Requirement already satisfied: anyio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.2.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.2)\n",
            "Requirement already satisfied: idna in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\programdata\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.1)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "LAkcBE5pebXv"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "graph = StateGraph(AgentState)\n",
        "\n",
        "graph.add_node(\"oracle\", run_oracle)\n",
        "graph.add_node(\"rag_search_filter\", run_tool)\n",
        "graph.add_node(\"rag_search\", run_tool)\n",
        "graph.add_node(\"report\", run_tool)\n",
        "# graph.add_node(\"web_search\", run_tool)\n",
        "graph.add_node(\"final_answer\", run_tool)\n",
        "\n",
        "graph.set_entry_point(\"oracle\")\n",
        "\n",
        "graph.add_conditional_edges(\n",
        "    source=\"oracle\",  # where in graph to start\n",
        "    path=router,  # function to determine which node is called\n",
        ")\n",
        "\n",
        "# create edges from each tool back to the oracle\n",
        "for tool_obj in tools:\n",
        "    if tool_obj.name != \"final_answer\":\n",
        "        graph.add_edge(tool_obj.name, \"oracle\")\n",
        "\n",
        "# if anything goes to final answer, it must then move to END\n",
        "graph.add_edge(\"final_answer\", END)\n",
        "\n",
        "runnable = graph.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: langchain_core in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (0.3.32)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langchain_core) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langchain_core) (0.3.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langchain_core) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langchain_core) (2.10.5)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain_core) (8.2.3)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langchain_core) (4.12.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (2.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_core) (0.27.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<0.4,>=0.1.125->langchain_core) (3.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<0.4,>=0.1.125->langchain_core) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_core) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_core) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain_core) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain_core) (2.27.2)\n",
            "Requirement already satisfied: anyio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (4.2.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (1.0.2)\n",
            "Requirement already satisfied: idna in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (3.10)\n",
            "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\programdata\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain_core) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aurel\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain_core) (2.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install the missing package\n",
        "%pip install langchain_core"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "EmwkoQkthb__",
        "outputId": "62a76d07-3576-498a-cf53-a1cb4dad57cb"
      },
      "outputs": [],
      "source": [
        "# # Install pygraphviz\n",
        "# %pip install pygraphviz==1.12 \n",
        "\n",
        "# from IPython.display import Image\n",
        "\n",
        "# Image(runnable.get_graph().draw_png())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmrXAdCwiN8N"
      },
      "source": [
        "## Building Reports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPJiet2niPnQ"
      },
      "source": [
        "Let's test our research agent. First, I want to try on something simple (although not within the intended use-case of our agent):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eghr8ZBI-IJL",
        "outputId": "7716c309-5ef8-4a95-8a93-0383c3a1140b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "run_oracle\n",
            "intermediate_steps: []\n",
            "rag_search_filter.invoke(input={'query': 'date de décès mère de Jean Lambert', 'author': 'Jean Lambert'})\n",
            "run_oracle\n",
            "intermediate_steps: [AgentAction(tool='rag_search_filter', tool_input={'query': 'date de décès mère de Jean Lambert', 'author': 'Jean Lambert'}, log='TBD'), AgentAction(tool='rag_search_filter', tool_input={'query': 'date de décès mère de Jean Lambert', 'author': 'Jean Lambert'}, log='Doc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page1_Chunk1\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page1_Chunk1\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page4_Chunk6\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page4_Chunk6\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page4_Chunk6\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page4_Chunk6\\n')]\n",
            "rag_search_filter.invoke(input={'query': 'date de décès mère de Jean Lambert', 'author': 'Jean Lambert'})\n",
            "run_oracle\n",
            "intermediate_steps: [AgentAction(tool='rag_search_filter', tool_input={'query': 'date de décès mère de Jean Lambert', 'author': 'Jean Lambert'}, log='TBD'), AgentAction(tool='rag_search_filter', tool_input={'query': 'date de décès mère de Jean Lambert', 'author': 'Jean Lambert'}, log='Doc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page1_Chunk1\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page1_Chunk1\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page4_Chunk6\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page4_Chunk6\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page4_Chunk6\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page4_Chunk6\\n'), AgentAction(tool='rag_search_filter', tool_input={'query': 'date de décès mère de Jean Lambert', 'author': 'Jean Lambert'}, log='TBD'), AgentAction(tool='rag_search_filter', tool_input={'query': 'date de décès mère de Jean Lambert', 'author': 'Jean Lambert'}, log='Doc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page1_Chunk1\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page1_Chunk1\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page4_Chunk6\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page4_Chunk6\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page4_Chunk6\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page4_Chunk6\\n')]\n",
            "rag_search_filter.invoke(input={'query': 'date de décès mère de Jean Lambert', 'author': 'Jean Lambert'})\n",
            "run_oracle\n",
            "intermediate_steps: [AgentAction(tool='rag_search_filter', tool_input={'query': 'date de décès mère de Jean Lambert', 'author': 'Jean Lambert'}, log='TBD'), AgentAction(tool='rag_search_filter', tool_input={'query': 'date de décès mère de Jean Lambert', 'author': 'Jean Lambert'}, log='Doc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page1_Chunk1\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page1_Chunk1\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page4_Chunk6\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page4_Chunk6\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page4_Chunk6\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page4_Chunk6\\n'), AgentAction(tool='rag_search_filter', tool_input={'query': 'date de décès mère de Jean Lambert', 'author': 'Jean Lambert'}, log='TBD'), AgentAction(tool='rag_search_filter', tool_input={'query': 'date de décès mère de Jean Lambert', 'author': 'Jean Lambert'}, log='Doc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page1_Chunk1\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page1_Chunk1\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page4_Chunk6\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page4_Chunk6\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page4_Chunk6\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page4_Chunk6\\n'), AgentAction(tool='rag_search_filter', tool_input={'query': 'date de décès mère de Jean Lambert', 'author': 'Jean Lambert'}, log='TBD'), AgentAction(tool='rag_search_filter', tool_input={'query': 'date de décès mère de Jean Lambert', 'author': 'Jean Lambert'}, log='Doc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page1_Chunk1\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page1_Chunk1\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page4_Chunk6\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page4_Chunk6\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page4_Chunk6\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page4_Chunk6\\n')]\n",
            "final_answer.invoke(input={'answer': 'Je ne sais pas la date précise du décès de la mère de Jean Lambert.', 'explore_next': 'Souhaitez-vous poser une autre question sur la famille ?', 'sources': None})\n"
          ]
        }
      ],
      "source": [
        "out = runnable.invoke({\n",
        "    \"input\": \"A quelle date précise est morte la mère de Jean Lambert?\",\n",
        "    \"chat_history\": [],\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjwDv5zvjACg"
      },
      "source": [
        "Let's create a function to consume the agent output and format it into our report:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "xZxjrfBfjFPl"
      },
      "outputs": [],
      "source": [
        "def build_report(output: dict):\n",
        "    research_steps = output[\"research_steps\"]\n",
        "    if type(research_steps) is list:\n",
        "        research_steps = \"\\n\".join([f\"- {r}\" for r in research_steps])\n",
        "    sources = output[\"sources\"]\n",
        "    if type(sources) is list:\n",
        "        sources = \"\\n\".join([f\"- {s}\" for s in sources])\n",
        "    return f\"\"\"\n",
        "INTRODUCTION\n",
        "------------\n",
        "{output[\"introduction\"]}\n",
        "\n",
        "RESEARCH STEPS\n",
        "--------------\n",
        "{research_steps}\n",
        "\n",
        "REPORT\n",
        "------\n",
        "{output[\"main_body\"]}\n",
        "\n",
        "CONCLUSION\n",
        "----------\n",
        "{output[\"conclusion\"]}\n",
        "\n",
        "SOURCES\n",
        "-------\n",
        "{sources}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjbPRhk8dhfs",
        "outputId": "5bd2070c-1f84-447a-c209-a9854e5af3b3"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'research_steps'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[76], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbuild_report\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mintermediate_steps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtool_input\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m)\u001b[49m)\n",
            "Cell \u001b[1;32mIn[75], line 2\u001b[0m, in \u001b[0;36mbuild_report\u001b[1;34m(output)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_report\u001b[39m(output: \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     research_steps \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresearch_steps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(research_steps) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m      4\u001b[0m         research_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m research_steps])\n",
            "\u001b[1;31mKeyError\u001b[0m: 'research_steps'"
          ]
        }
      ],
      "source": [
        "print(build_report(\n",
        "    output=out[\"intermediate_steps\"][-1].tool_input\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBgBR3PdiXIg"
      },
      "source": [
        "Now let's try with an on-topic question on AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a21f9VneePw_",
        "outputId": "49ebe6a1-16e0-46fb-f0a5-7fae3e2c1f3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "run_oracle\n",
            "intermediate_steps: []\n",
            "rag_search.invoke(input={'query': 'La Belle au bois dormant'})\n",
            "run_oracle\n",
            "intermediate_steps: [AgentAction(tool='rag_search', tool_input={'query': 'La Belle au bois dormant'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'La Belle au bois dormant'}, log=\"Doc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nSummary: Table des matières détaillant les chapitres et annexes d'un ouvrage sur l'affaire Dreyfus et la vie personnelle et professionnelle de l'auteur. Les chapitres couvrent des thèmes tels que l'antisémitisme, la vie familiale, les activités professionnelles entre 1903 et 1914, et les expériences durant la Première Guerre mondiale. Les annexes incluent des réflexions, des notes historiques sur les juifs, des documents personnels, des photos, et des éléments de généalogie. Le volume 2 contient des documents supplémentaires et annonce un projet pour un tome sur la famille maternelle et des souvenirs personnels.\\nChunk_ID: Pour la mémoire familiale 1-50_Page5_Chunk4\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nSummary: Table des matières détaillant les chapitres et annexes d'un ouvrage sur la vie d'un père, abordant des thèmes tels que l'affaire Dreyfus, la vie personnelle et professionnelle entre 1903 et 1914, et les expériences durant la guerre de 1914-1918. Inclut des réflexions sur l'antisémitisme, le racisme, et l'histoire des Juifs en France, ainsi que des souvenirs et documents personnels. Le volume 2 contient des annexes avec cartes, généalogie, photos, et documents d'état-civil. Un projet de tome II sur la famille maternelle et un tome III sur des souvenirs personnels sont également mentionnés.\\nChunk_ID: Pour la mémoire familiale 1-50_Page5_Chunk4\\n\")]\n",
            "final_answer.invoke(input={'answer': 'I couldn\\'t find any specific information about \"La Belle au bois dormant\" in the family database. The available documents focus more on historical themes, personal experiences, and genealogical information rather than specific literary works.', 'explore_next': 'Would you like to search for information on another topic or a different literary work?', 'sources': None})\n"
          ]
        }
      ],
      "source": [
        "out = runnable.invoke({\n",
        "    \"input\": \"Do we have info about La Belle au bois dormant in the family database?\",\n",
        "    \"chat_history\": []\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vis78CFR3puz"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'research_steps'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[111], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbuild_report\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mintermediate_steps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtool_input\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m)\u001b[49m)\n",
            "Cell \u001b[1;32mIn[93], line 2\u001b[0m, in \u001b[0;36mbuild_report\u001b[1;34m(output)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_report\u001b[39m(output: \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     research_steps \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresearch_steps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(research_steps) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m      4\u001b[0m         research_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m research_steps])\n",
            "\u001b[1;31mKeyError\u001b[0m: 'research_steps'"
          ]
        }
      ],
      "source": [
        "print(build_report(\n",
        "    output=out[\"intermediate_steps\"][-1].tool_input\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNyxZL4SNjhX"
      },
      "source": [
        "Let's ask about RAG specifically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "x0VmnWlWE6Lg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "run_oracle\n",
            "intermediate_steps: []\n",
            "rag_search.invoke(input={'query': 'Francis'})\n",
            "run_oracle\n",
            "intermediate_steps: [AgentAction(tool='rag_search', tool_input={'query': 'Francis'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'Francis'}, log='Doc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page12_Chunk3\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page12_Chunk3\\n')]\n",
            "rag_search_filter.invoke(input={'query': 'Francis', 'author': 'Jean Lambert'})\n",
            "run_oracle\n",
            "intermediate_steps: [AgentAction(tool='rag_search', tool_input={'query': 'Francis'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'Francis'}, log='Doc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page12_Chunk3\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page12_Chunk3\\n'), AgentAction(tool='rag_search_filter', tool_input={'query': 'Francis', 'author': 'Jean Lambert'}, log='TBD'), AgentAction(tool='rag_search_filter', tool_input={'query': 'Francis', 'author': 'Jean Lambert'}, log='Doc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page12_Chunk3\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page12_Chunk3\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page4_Chunk7\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page4_Chunk7\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page4_Chunk7\\n\\n---\\nDoc name: Pour la mémoire familiale 1-50\\nAuthor: Jean Lambert\\nChunk_ID: Pour la mémoire familiale 1-50_Page4_Chunk7\\n')]\n",
            "final_answer.invoke(input={'answer': 'Je ne sais pas qui est Francis. Les informations disponibles dans la mémoire familiale ne fournissent pas de détails à son sujet.', 'explore_next': 'Souhaitez-vous en savoir plus sur un autre membre de la famille ou un événement spécifique ?', 'sources': None})\n"
          ]
        }
      ],
      "source": [
        "out = runnable.invoke({\n",
        "    \"input\": \"Qui est Francis?\",\n",
        "    \"chat_history\": []\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'runnable' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mrunnable\u001b[49m\u001b[38;5;241m.\u001b[39minvoke({\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms the history of the Dreyfus?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m: []\n\u001b[0;32m      4\u001b[0m })\n",
            "\u001b[1;31mNameError\u001b[0m: name 'runnable' is not defined"
          ]
        }
      ],
      "source": [
        "out = runnable.invoke({\n",
        "    \"input\": \"What's the history of the Dreyfus?\",\n",
        "    \"chat_history\": []\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rp2uaRW7cAoM"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
