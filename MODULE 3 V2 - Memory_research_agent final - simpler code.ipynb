{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Memory Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Load path from the environment variable\n",
    "env_ih1 = os.getenv(\"ENV_IH1\")\n",
    "\n",
    "dotenv_path = Path(env_ih1)\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY= os.getenv('PINECONE_KEY')\n",
    "SERPAPI_API_KEY = os.getenv('SERPAPI_API_KEY')\n",
    "STEAMSHIP_API_KEY = os.getenv('STEAMSHIP_API_KEY')\n",
    "LANGSMITH_API_KEY = os.getenv('LANGSMITH_API_KEY')\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
    "GEMINI_KEY = os.getenv('GEMINI_KEY')\n",
    "\n",
    "os.environ['PATH'] += os.pathsep + '/usr/bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import wrappers, traceable\n",
    "\n",
    "LANGSMITH_API_KEY= LANGSMITH_API_KEY\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"memory-project\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pinecone DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 170}},\n",
       " 'total_vector_count': 170}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# configure client\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Connect to the existing index\n",
    "index_name = \"memory-project4\"  # Replace with your existing index name\n",
    "# connect to index\n",
    "index = pc.Index(index_name)\n",
    "time.sleep(1)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone as LangchainPinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "## Create encoder\n",
    "from semantic_router.encoders import OpenAIEncoder\n",
    "\n",
    "encoder = OpenAIEncoder(\n",
    "    name=\"text-embedding-3-small\",\n",
    "    openai_api_key=OPENAI_API_KEY \n",
    ")\n",
    "\n",
    "## Creating retriever\n",
    "\n",
    "# Initialize OpenAI Embeddings with text-embedding-3-small\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\", openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Initialize LangChain Pinecone retriever\n",
    "vectorstore = LangchainPinecone(index, embeddings, text_key=\"text\")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: pas exact , en raison de l'importance de son commerce . Je dirais plutôt négociant en tissus , en précisant qu'il l'exerçait en ambulant . Il avait pour cela une voiture à deux chevaux assez spacieuse et confortable . Il était propriétaire de l'ensemble , ce qui paraît assez rare dans cette profession à cette époque . Il faisait des tournées d'environ six mois et son itinéraire comportait beaucoup de petits bourgs qui n'étaient pas desservis par les diligences . C'est à dire qu'il voyageait en zigzag autour de la grande route . Il ne faisait pas les marchés , mais approvisionnait les revendeurs . POUR LA MÉMOIRE FAMILIALE FAMILLE HISTOIRE SOUVENIRS & COMMENTAIRES VOLUME 1 Jean-Georges Lambert Avril 1993 J'ai entrepris ce travail pour mes fils qui tiennent à parts égales, tant de place dans ma vie.  Je veux l'offrir aussi à mes belles-filles pour les remercier, chacune, d'être ce qu'elles sont.\n",
      "Metadata: {'Author': 'Jean Lambert', 'Chunk_ID': 'Pour la mémoire familiale 1-50_Chunk1', 'Doc name': 'Pour la mémoire familiale 1-50', 'Page_number': 1.0, 'Total_Chunks': 1.0}\n",
      "--------------------------------------------------\n",
      "Content: de colporteur . C'est le terme qu'employait mon père , mais je pense qu'il n'est pas exact , en raison de l'importance de son commerce . Je dirais plutôt négociant en tissus , en précisant qu'il l'exerçait en ambulant . Il avait pour cela une voiture à deux chevaux assez spacieuse et confortable . Il était propriétaire de l'ensemble , ce qui paraît assez rare dans cette profession à cette époque . Il faisait des tournées d'environ six mois et son itinéraire comportait beaucoup de petits bourgs qui n'étaient pas desservis par les diligences . C'est à dire qu'il voyageait en zigzag autour de la grande route . Il ne faisait pas les marchés , mais approvisionnait les revendeurs . POUR LA MÉMOIRE\n",
      "FAMILIALE\n",
      "\n",
      "FAMILLE HISTOIRE\n",
      "SOUVENIRS & COMMENTAIRES\n",
      "\n",
      "VOLUME 1\n",
      "\n",
      "Jean-Georges Lambert\n",
      "Avril 1993\n",
      "Metadata: {'Author': 'Jean Lambert', 'Chunk_ID': 'Pour la mémoire familiale 1-50_Chunk1', 'Doc name': 'Pour la mémoire familiale 1-50', 'Page_number': 1.0, 'Total_Chunks': 1.0}\n",
      "--------------------------------------------------\n",
      "Content: . Il était propriétaire de l'ensemble , ce qui paraît assez rare dans cette profession à cette époque . Il faisait des tournées d'environ six mois et son itinéraire comportait beaucoup de petits bourgs qui n'étaient pas desservis par les diligences . C'est à dire qu'il voyageait en zigzag autour de la grande route . Il ne faisait pas les marchés , mais approvisionnait les revendeurs . POUR LA MÉMOIRE FAMILIALE FAMILLE HISTOIRE SOUVENIRS & COMMENTAIRES VOLUME 1 Jean-Georges Lambert Avril 1993 J'ai entrepris ce travail pour mes fils qui tiennent à parts égales , tant de place dans ma vie . Je veux l'offrir aussi à mes belles-filles pour les remercier , chacune , d'être ce qu'elles sont . VOLUME 1\n",
      "\n",
      "Page\n",
      "6- Préambule.\n",
      "\n",
      "TABLE DES MATIERES DES VOLUMES 1 & 2\n",
      "-TONE 1-MA FAMILLE PATERNELLE -\n",
      "\n",
      "11 Préambule du Tome I.\n",
      "\n",
      "18 PREMIERE PARTIE : Pour faire le point au temps de ma jeunesse\n",
      "\n",
      "19-Chapitre I: Objet de cette première partie.\n",
      "\n",
      "20-Chapitre II: Un climat passionnel.\n",
      "-Le génocide nazi -L'antisémitisme dans le monde arabe et musulman -L'édition et les\n",
      "médias -Conséquence de ce qui précéde La résurgence du nazisme\n",
      "\n",
      "25-Chapitre III: Les Juifs entre les deux querre\n",
      "-Le temps de ma jeunesse -Les préjugés entre français -L'attitude envers les étrangers\n",
      "-Les juifs allemands -L'antisémitisme en France entre les deux guerres -L'antisémitisme\n",
      "en France pendant la guerre de 1940-45 -A propos des raffles et arrestations de juifs\n",
      "Respecter les français -Additif à propos de la raffle du Vel'd'Hiv.\n",
      "\n",
      "39-Chapitre IV: Le protestantisme Le patriotisme.\n",
      "\n",
      "41 DEUXIEME PARTIE: Réflexion sur l'histoire des juifs.\n",
      "\n",
      "42 -Chapitre V: De l'origine de la Diaspora à l'Empire Romain.\n",
      "-Pourquoi chercher si loin -La Diaspora La population juive à l'époque du Christ -Les\n",
      "juifs dans le monde gréco-romain -Les juifs en Palestune après la mort du Christ -Les\n",
      "juifs en Gaule et sur les bords du Rhin -La montée du christianisme et la naissance de\n",
      "l'antijudaisme chrétien\n",
      "\n",
      "50 -Chapitre VI: De l'Empire Romain à l'an 1000.\n",
      "-De l'arrivée des barbares au VII siècle -L'Empire Carolingien du VIII au Xº siéles\n",
      "Le judaisme et l'activité intellectuelle des juifs\n",
      "\n",
      "53 -Chapitre VII: Du XI au XVe siècles.\n",
      "-La situation des juifs au début du IIº millénaire L'évolution de la situation - Le\n",
      "renforcement des mesures contre les juifs -Les croisades et la peste noire -L'exil -Le\n",
      "sort des juifs du royaume de France dans le contexte historique La situation des juifs\n",
      "en Alsace et en Lorraine du XIème au XVème siècle- Les juifs dans les pays de l'est.\n",
      "\n",
      "59 -Chapitre VIII: Du XVIème siècle à la Révolution.\n",
      "-La situation en France au début du XVI siècle -Le retour des juifs en Occident -\n",
      "L'évolution, en France, des mentalités et des attitudes vis à vis de juifs -Les\n",
      "communautés juives en France Les Marranes Les contadins et les avignonais -L'histoire\n",
      "avec un grand Het la petite histoire de la famille Les juifs de Lorraine -Les juifs\n",
      "d'Alsace -Les communautés de Lorraine et d'Alsace, la religion, et les rapports avec\n",
      "les populations -Les juifs de Paris Le pouvoir roval et les juifs -Quelques remarques\n",
      "sur la situation des juifs avant la Révolution.\n",
      "\n",
      "74 -Chapitre IX\n",
      ": La Révolution et le Directoire.\n",
      "-Ma rencontre avec cette période de l'histoire La France des communautés La situation\n",
      "morale de juifs en France -L'abbé Grégoire -Les Assemblées et les juifs Les étapes de\n",
      "la Révolutions: -Les Etats Généraux et la Constituante (1789-30/9/91)\n",
      "Metadata: {'Author': 'Jean Lambert', 'Chunk_ID': 'Pour la mémoire familiale 1-50_Chunk1', 'Doc name': 'Pour la mémoire familiale 1-50', 'Page_number': 2.0, 'Total_Chunks': 2.0}\n",
      "--------------------------------------------------\n",
      "Content: de Maman Michel, et il est mort à Reims le 4 mars 1893 âgé de soixante quatre ans.\n",
      "\n",
      "Son influence sur la famille est de plus courte durée que celle de Maman Michel, mais c'est aussi une forte personnalité qui a joué un rôle important dans le déroulement de la vie familiale.\n",
      "\n",
      "L'histoire de Jacques Dreyfus commence à l'époque où il exerçait la profession de colporteur. C'est le terme qu'employait mon père, mais je pense qu'il n'est pas exact, en raison de l'importance de son commerce. Je dirais plutôt négociant en tissus, en précisant qu'il l'exerçait en ambulant. Il avait pour cela une voiture à deux chevaux assez spacieuse et confortable. Il était propriétaire de l'ensemble, ce qui paraît assez rare dans cette profession à cette époque. Il faisait des tournées d'environ six mois et son itinéraire comportait beaucoup de petits bourgs qui n'étaient pas desservis par les diligences. C'est à dire qu'il voyageait en zigzag autour de la grande route. Il ne faisait pas les marchés, mais approvisionnait les revendeurs.\n",
      "Metadata: {'Author': 'John Doe', 'Chunk_ID': 'Pdf img_Chunk2', 'Doc name': 'Pdf img', 'Page_number': 118.0, 'Total_Chunks': 2.0}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test retrieval\n",
    "query = \"Who is Jean Lambert?\"\n",
    "results = retriever.get_relevant_documents(query)\n",
    "\n",
    "# Print results\n",
    "for doc in results:\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "text_field = \"text\"  # the metadata field that contains our text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from pprint import pformat\n",
    "import ast\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from typing import List, Union\n",
    "from langchain.tools import tool\n",
    "import re\n",
    "\n",
    "\n",
    "# Defining Tools\n",
    "##################################################################################\n",
    "\n",
    "def format_rag_contexts(matches: list):\n",
    "    \"\"\"Formats retrieved document matches into a readable context string.\"\"\"\n",
    "    contexts = []\n",
    "    for x in matches:\n",
    "        metadata = x.get(\"metadata\", {})  # Safely get metadata\n",
    "        text = (\n",
    "            f\"Doc name: {metadata.get('Doc name', 'N/A')}\\n\"\n",
    "            f\"Author: {metadata.get('Author', 'N/A')}\\n\"\n",
    "            f\"Chunk_ID: {metadata.get('Chunk_ID', 'N/A')}\\n\"\n",
    "            f\"Content: {metadata.get('text', 'No content available')}\"  # Fixed page content reference\n",
    "        )\n",
    "        contexts.append(text)\n",
    "\n",
    "    return \"\\n---\\n\".join(contexts)\n",
    "\n",
    "\n",
    "def translate_to_french(query: str):\n",
    "    \"\"\"Translates the given query to French using OpenAI's `o4-mini` model to improve retriebal in French database.\"\"\"\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o\",  # \"o4-mini\" may refer to \"gpt-4o\"\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a translation assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Translate the following text to French:\\n{query}\"}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "# Tool for RAG search\n",
    "def rag_search(query: str):\n",
    "    \"\"\"Finds relevant information using a natural language query and retrieves ±3 context chunks.\"\"\"\n",
    "    \n",
    "    results = retriever.get_relevant_documents(query, k=10)\n",
    "    if not results:\n",
    "        return \"⚠ No relevant documents found.\"\n",
    "\n",
    "    best_match = results[0].metadata\n",
    "    doc_name = best_match.get(\"Doc name\", \"\")\n",
    "    chunk_id = best_match.get(\"Chunk_ID\", \"\")\n",
    "    total_chunks = int(best_match.get(\"Total_Chunks\", 1))\n",
    "\n",
    "    match = re.match(r\"(.+)_Chunk(\\d+)\", chunk_id)\n",
    "    if not match:\n",
    "        return results  \n",
    "\n",
    "    _, chunk_num = match.groups()\n",
    "    chunk_num = int(chunk_num)\n",
    "\n",
    "    # Generate surrounding chunk IDs (-3 to +3, within range)\n",
    "    expanded_chunk_ids = [f\"{doc_name}_Chunk{i}\" for i in range(max(1, chunk_num - 3), min(total_chunks, chunk_num + 3) + 1)]\n",
    "\n",
    "    # Retrieve only matching expanded chunks\n",
    "    expanded_results = [\n",
    "        doc for doc in retriever.get_relevant_documents(query, k=6)\n",
    "        if doc.metadata.get(\"Chunk_ID\") in expanded_chunk_ids\n",
    "    ]\n",
    "\n",
    "    # Remove duplicates based on `Chunk_ID`\n",
    "    unique_chunks = {doc.metadata[\"Chunk_ID\"]: doc.page_content for doc in expanded_results}\n",
    "\n",
    "    return \"\\n\\n\".join(unique_chunks.values()) if unique_chunks else \"⚠ No context found.\"\n",
    "\n",
    "\n",
    "\n",
    "def final_answer(answer: str, explore_next: str = \"Would you like to ask about another topic?\", sources: str = None):\n",
    "    \"\"\"\n",
    "    Formats the final answer using a structured approach.\n",
    "\n",
    "    Args:\n",
    "        answer (str): The main response.\n",
    "        explore_next (str, optional): Suggested next question.\n",
    "        sources (str, optional): Source references.\n",
    "\n",
    "    Returns:\n",
    "        str: A well-structured response.\n",
    "    \"\"\"\n",
    "\n",
    "    # 🔹 Construct sources section only if sources are available\n",
    "    sources_section = f\"- **Sources**: {sources}\" if sources and sources.lower() != 'none' else \"\"\n",
    "\n",
    "    # 🔹 Define the structured prompt within the function\n",
    "    final_answer_prompt = PromptTemplate.from_template(\"\"\"\n",
    "    You are an intelligent assistant helping with historical research.\n",
    "    Format the final answer for the user by including:\n",
    "\n",
    "    - **Answer**: {answer}\n",
    "    {sources_section}\n",
    "    - **Explore Next**: {explore_next}\n",
    "\n",
    "    Ensure the response is clear and well-structured.\n",
    "    \"\"\")\n",
    "\n",
    "    # 🔹 Ensure all fields are properly formatted before passing to the prompt\n",
    "    structured_input = {\n",
    "        \"answer\": answer,\n",
    "        \"explore_next\": explore_next if explore_next else \"No further suggestions.\",\n",
    "        \"sources_section\": sources_section\n",
    "    }\n",
    "\n",
    "    # 🔹 Use the embedded prompt template to format the response\n",
    "    formatted_response = final_answer_prompt.format(**structured_input)\n",
    "\n",
    "    return formatted_response  # ✅ Always returns a well-structured response\n",
    "\n",
    "\n",
    "\n",
    "# Binding tools to the LLM\n",
    "##################################################################################\n",
    "\n",
    "# Create tool bindings with additional attributes\n",
    "from langchain.tools import Tool\n",
    "\n",
    "# # Tool for formatting RAG contexts\n",
    "# format_rag_contexts_tool = Tool.from_function(\n",
    "#     func=format_rag_contexts,\n",
    "#     name=\"format_rag_contexts\",\n",
    "#     description=\"Formats retrieved document matches into a readable context string.\",\n",
    "#     return_direct=False\n",
    "# )\n",
    "\n",
    "# Tool for translating text to French\n",
    "translate_to_french_tool = Tool.from_function(\n",
    "    func=translate_to_french,\n",
    "    name=\"translate_to_french\",\n",
    "    description=\"Translates the given query to French using OpenAI's GPT-4o model to improve retrieval in a French database.\",\n",
    "    return_direct=False\n",
    ")\n",
    "\n",
    "# Tool for RAG search\n",
    "rag_search_tool = Tool.from_function(\n",
    "    func=rag_search,\n",
    "    name=\"rag_search\",\n",
    "    description=\"Finds related information using a natural language query in the family history database.\",\n",
    "    return_direct=False\n",
    ")\n",
    "\n",
    "# # Tool for chunk search\n",
    "# chunk_search_tool = Tool.from_function(\n",
    "#     func=chunk_search,\n",
    "#     name=\"chunk_search\",\n",
    "#     description=\"Finds related information based on the chunk_id, helping to get more context around a given chunk.\",\n",
    "#     return_direct=False\n",
    "# )\n",
    "\n",
    "# Tool for final answer generation\n",
    "final_answer_tool = Tool.from_function(\n",
    "    func=final_answer,\n",
    "    name=\"final_answer\",\n",
    "    description=(\n",
    "        \"Generates a natural language response to the user's question based on the family memory database. \"\n",
    "        \"Links information together from multiple sources but does not invent new information. \"\n",
    "        \"If no answer is found, it explicitly states that it doesn't know.\"\n",
    "    ),\n",
    "    return_direct=False\n",
    ")\n",
    "\n",
    "# List of all tools\n",
    "toolbox = [\n",
    "    translate_to_french_tool,\n",
    "    rag_search_tool,\n",
    "    final_answer_tool\n",
    "]\n",
    "\n",
    "\n",
    "# OPENAI_API_KEY environment variable must be set\n",
    "simple_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm_with_tools = simple_llm.bind_tools(toolbox)\n",
    "\n",
    "\n",
    "# Defining Agent's node\n",
    "##################################################################################\n",
    "\n",
    "# System message\n",
    "assistant_system_message = SystemMessage(content=(\"\"\"You are the Family Safe, keeper of the family's collective memory. \n",
    "Your role is to decide how to handle user queries using the available tools.\n",
    "\n",
    "**Tool Usage:**\n",
    "- Do NOT reuse a tool for the same query.\n",
    "- Do NOT use any tool more than **5 times**.\n",
    "- Prioritize **rag_search** for gathering information.\n",
    "- Do not mix sources from different contexts unless necessary.\n",
    "- Alsways check at leats 2 ***Doc name*** to ensure the information is correct.\n",
    "\n",
    "**Response Protocol:**\n",
    "- If tools provides no answer, state that you don't know or can't any information about this topic\"\n",
    "- NEVER invent information or use data beyond the family memory.\n",
    "- Always provide sources via the **final_answer** tool.\n",
    "- Chunk_search must be in the scracthpad to point to final_answer.\n",
    "- Discard any page content that looks like a table of content: you won't find any useful information there apart from page numbers.\n",
    "\n",
    "By following these rules, you ensure accurate and responsible responses.\"\"\"))\n",
    "\n",
    "# Node\n",
    "def assistant(state: MessagesState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([assistant_system_message] + state[\"messages\"])]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Defining Graph\n",
    "##################################################################################\n",
    "\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(toolbox))\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "react_graph_with_memory = builder.compile(checkpointer=memory)\n",
    "\n",
    "# Show\n",
    "display(Image(react_graph_with_memory.get_graph(xray=True).draw_mermaid_png()))\n",
    "\n",
    "# Define oracle function\n",
    "################################################################################################\n",
    "\n",
    "# Specify a thread\n",
    "def oracle(user_request: str, thread_id = \"1\", verbose = False):\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    messages = react_graph_with_memory.invoke({\"messages\": [HumanMessage(content=user_request)]}, config)\n",
    "    if verbose:\n",
    "        for message in messages['messages']:\n",
    "            message.pretty_print()\n",
    "    else:\n",
    "        messages['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "- **Answer**: Oui, il a des frères et sœurs. Louis et Rachel, ses parents, ont eu six enfants: Charlotte, Jacques, Alexandre, Lehmann (ou Clément), Marx, et Julie. Notre ancêtre direct est Lehmann, né en 1800.\n",
      "\n",
      "- **Explore Next**: Would you like to ask about another topic?\n"
     ]
    }
   ],
   "source": [
    "oracle(\n",
    "    user_request=\"Does he have siblings?\", \n",
    "    thread_id=\"300\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "**Answer**: I couldn't find specific information regarding when Jean started to write his book. The details may not be available in the family history database.\n",
      "\n",
      "**Explore Next**: Would you like to ask about another topic?\n"
     ]
    }
   ],
   "source": [
    "oracle(\n",
    "    user_request=\"When did Jean start to write this book?\", \n",
    "    thread_id=\"5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "**Answer**: Jean's mother died on March 29, 1963.\n",
      "\n",
      "**Explore Next**: Would you like to ask about another topic?\n"
     ]
    }
   ],
   "source": [
    "oracle(\n",
    "    user_request=\"When did Jean's mother died?\", \n",
    "    thread_id=\"5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "**Answer**: I don’t know any specific information about Elon Musk.\n",
      "\n",
      "**Explore Next**: Would you like to ask about another topic?\n"
     ]
    }
   ],
   "source": [
    "oracle(\n",
    "    user_request=\"Who is Elon Musk?\", \n",
    "    thread_id=\"70\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "**Answer**: Jean a eu 6 enfants : Charlotte, Jacques, Alexandre, Lehmann (ou Clément), Marx et Julie. Ces enfants sont nés à Froeningen entre 1795 et 1802.\n",
      "\n",
      "**Explore Next**: Would you like to ask about another topic?\n"
     ]
    }
   ],
   "source": [
    "oracle(\n",
    "    user_request=\"Combien d'enfant a Jean?\", \n",
    "    thread_id=\"9\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "### Answer:\n",
      "In the documents related to 'sons' from chunks 7 and 8, there is no specific mention or detailed information about any sons. The content primarily revolves around the author's reflections on their upbringing, family history, and their mother's death. Unfortunately, this content does not contain pertinent information about sons within these specific chunks.\n",
      "\n",
      "### Explore Next:\n",
      "Would you like to ask about another topic?\n"
     ]
    }
   ],
   "source": [
    "oracle(\n",
    "    user_request=\"Can you check for sons in chunk 7 & 8?\", \n",
    "    thread_id=\"7\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "- **Answer**: Jean's sentiments appear to involve a nuanced view of Jewish communities, acknowledging challenges and advocating for their rights and recognition. He highlights the moral responsibility of society to improve their situation, suggesting that Judaism should not be seen in a negative light and emphasizes the importance of respect and recognition of individuals in the community.\n",
      "\n",
      "- **Explore Next**: Would you like to ask about another topic?\n"
     ]
    }
   ],
   "source": [
    "oracle(\n",
    "    user_request=\"What does Jean has to say about it?\", \n",
    "    thread_id=\"8\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "**Answer**: The personal anecdotes reflect a rich tapestry of family history, emphasizing the dramatic changes in cultural values and traditions over generations. The narrator shares insights from their father's notes, revealing a serene perspective on Jewish identity and societal norms from the past, contrasting sharply with contemporary views. They discuss the significance of life events, such as birth and death, and how societal attitudes have evolved, particularly regarding mourning practices and the impact of war. These reflections serve as a bridge between generations, illustrating the profound influence of historical context on personal experiences and family legacies.\n",
      "\n",
      "**Explore Next**: Would you like to ask about another topic?\n"
     ]
    }
   ],
   "source": [
    "oracle(\n",
    "    user_request=\"Expand on his personal anecdotes\", \n",
    "    thread_id=\"5052\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurel\\AppData\\Roaming\\Python\\Python312\\site-packages\\gradio\\components\\chatbot.py:282: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# Initialize conversation history\n",
    "chat_history = []\n",
    "\n",
    "def query_oracle(user_request: str):\n",
    "    \"\"\"Invokes the LangGraph Oracle and returns a structured response.\"\"\"\n",
    "    global chat_history\n",
    "\n",
    "    try:\n",
    "        # Invoke Oracle using LangGraph with memory\n",
    "        config = {\"configurable\": {\"thread_id\": \"29\"}}\n",
    "        response = react_graph_with_memory.invoke({\"messages\": [HumanMessage(content=user_request)]}, config)\n",
    "\n",
    "        # Extract latest message (handle None case)\n",
    "        response_text = response[\"messages\"][-1].content if response and \"messages\" in response else \"⚠ No valid response.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        response_text = f\"🚨 Error: {str(e)}\"\n",
    "\n",
    "    # Store user input and Oracle response as tuple\n",
    "    chat_history.append((user_request, response_text))\n",
    "    return chat_history  # Return updated chat history for Gradio Chatbot\n",
    "\n",
    "# Function to clear chat history\n",
    "def clear_chat():\n",
    "    global chat_history\n",
    "    chat_history = []  # Reset chat history\n",
    "    return chat_history  # Reset chatbot UI\n",
    "\n",
    "# Set up Gradio Interface\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# 🔮 LangGraph Oracle Assistant\")\n",
    "    gr.Markdown(\"Ask any question about your family history, and the Oracle will respond.\")\n",
    "\n",
    "    chatbot = gr.Chatbot(label=\"Chat History\")  # Chat interface\n",
    "\n",
    "    with gr.Row():\n",
    "        user_input = gr.Textbox(label=\"Your Question\", placeholder=\"Type your question here...\", lines=1)\n",
    "        submit_button = gr.Button(\"Submit\")\n",
    "\n",
    "    # Clear Chat Button\n",
    "    clear_button = gr.Button(\"Clear Chat\")\n",
    "\n",
    "    # Connect Buttons to Functions\n",
    "    submit_button.click(query_oracle, inputs=[user_input], outputs=[chatbot])\n",
    "    clear_button.click(clear_chat, inputs=None, outputs=[chatbot])  # Clears the chat\n",
    "\n",
    "# Launch Gradio App\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 [DEBUG] Query received: Hello! How can you help me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! I can assist you with queries related to family history, collective memories, and other related topics. If you have any specific questions or topics you'd like to know more about, feel free to ask!\n",
      "📡 [DEBUG] Raw Oracle response: None\n",
      "🔍 [DEBUG] Type of response: <class 'NoneType'>\n",
      "⚠ [DEBUG] Oracle returned None. Possible failure in agent processing.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'⚠ No response received from Oracle. Please try again.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def query_oracle(text: str):\n",
    "    \"\"\"Invokes the LangGraph agent and extracts a cleaned response.\"\"\"\n",
    "    print(f\"🔍 [DEBUG] Query received: {text}\")\n",
    "\n",
    "    response = oracle(user_request=text, thread_id=\"500\")\n",
    "\n",
    "    print(f\"📡 [DEBUG] Raw Oracle response: {response}\")\n",
    "    print(f\"🔍 [DEBUG] Type of response: {type(response)}\")\n",
    "\n",
    "    if response is None:\n",
    "        print(\"⚠ [DEBUG] Oracle returned None. Possible failure in agent processing.\")\n",
    "        return \"⚠ No response received from Oracle. Please try again.\"\n",
    "\n",
    "    return response\n",
    "\n",
    "query_oracle(\"Hello! How can you help me?\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
