{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Memory Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Load path from the environment variable\n",
    "env_ih1 = os.getenv(\"ENV_IH1\")\n",
    "\n",
    "dotenv_path = Path(env_ih1)\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY= os.getenv('PINECONE_KEY')\n",
    "SERPAPI_API_KEY = os.getenv('SERPAPI_API_KEY')\n",
    "STEAMSHIP_API_KEY = os.getenv('STEAMSHIP_API_KEY')\n",
    "LANGSMITH_API_KEY = os.getenv('LANGSMITH_API_KEY')\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
    "GEMINI_KEY = os.getenv('GEMINI_KEY')\n",
    "\n",
    "os.environ['PATH'] += os.pathsep + '/usr/bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import wrappers, traceable\n",
    "\n",
    "LANGSMITH_API_KEY= LANGSMITH_API_KEY\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"memory-project\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pinecone DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 170}},\n",
       " 'total_vector_count': 170}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# configure client\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Connect to the existing index\n",
    "index_name = \"memory-project4\"  # Replace with your existing index name\n",
    "# connect to index\n",
    "index = pc.Index(index_name)\n",
    "time.sleep(1)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone as LangchainPinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "## Create encoder\n",
    "from semantic_router.encoders import OpenAIEncoder\n",
    "\n",
    "encoder = OpenAIEncoder(\n",
    "    name=\"text-embedding-3-small\",\n",
    "    openai_api_key=OPENAI_API_KEY \n",
    ")\n",
    "\n",
    "## Creating retriever\n",
    "\n",
    "# Initialize OpenAI Embeddings with text-embedding-3-small\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\", openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Initialize LangChain Pinecone retriever\n",
    "vectorstore = LangchainPinecone(index, embeddings, text_key=\"text\")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: pas exact , en raison de l'importance de son commerce . Je dirais plut√¥t n√©gociant en tissus , en pr√©cisant qu'il l'exer√ßait en ambulant . Il avait pour cela une voiture √† deux chevaux assez spacieuse et confortable . Il √©tait propri√©taire de l'ensemble , ce qui para√Æt assez rare dans cette profession √† cette √©poque . Il faisait des tourn√©es d'environ six mois et son itin√©raire comportait beaucoup de petits bourgs qui n'√©taient pas desservis par les diligences . C'est √† dire qu'il voyageait en zigzag autour de la grande route . Il ne faisait pas les march√©s , mais approvisionnait les revendeurs . POUR LA M√âMOIRE FAMILIALE FAMILLE HISTOIRE SOUVENIRS & COMMENTAIRES VOLUME 1 Jean-Georges Lambert Avril 1993 J'ai entrepris ce travail pour mes fils qui tiennent √† parts √©gales, tant de place dans ma vie.  Je veux l'offrir aussi √† mes belles-filles pour les remercier, chacune, d'√™tre ce qu'elles sont.\n",
      "Metadata: {'Author': 'Jean Lambert', 'Chunk_ID': 'Pour la m√©moire familiale 1-50_Chunk1', 'Doc name': 'Pour la m√©moire familiale 1-50', 'Page_number': 1.0, 'Total_Chunks': 1.0}\n",
      "--------------------------------------------------\n",
      "Content: de colporteur . C'est le terme qu'employait mon p√®re , mais je pense qu'il n'est pas exact , en raison de l'importance de son commerce . Je dirais plut√¥t n√©gociant en tissus , en pr√©cisant qu'il l'exer√ßait en ambulant . Il avait pour cela une voiture √† deux chevaux assez spacieuse et confortable . Il √©tait propri√©taire de l'ensemble , ce qui para√Æt assez rare dans cette profession √† cette √©poque . Il faisait des tourn√©es d'environ six mois et son itin√©raire comportait beaucoup de petits bourgs qui n'√©taient pas desservis par les diligences . C'est √† dire qu'il voyageait en zigzag autour de la grande route . Il ne faisait pas les march√©s , mais approvisionnait les revendeurs . POUR LA M√âMOIRE\n",
      "FAMILIALE\n",
      "\n",
      "FAMILLE HISTOIRE\n",
      "SOUVENIRS & COMMENTAIRES\n",
      "\n",
      "VOLUME 1\n",
      "\n",
      "Jean-Georges Lambert\n",
      "Avril 1993\n",
      "Metadata: {'Author': 'Jean Lambert', 'Chunk_ID': 'Pour la m√©moire familiale 1-50_Chunk1', 'Doc name': 'Pour la m√©moire familiale 1-50', 'Page_number': 1.0, 'Total_Chunks': 1.0}\n",
      "--------------------------------------------------\n",
      "Content: . Il √©tait propri√©taire de l'ensemble , ce qui para√Æt assez rare dans cette profession √† cette √©poque . Il faisait des tourn√©es d'environ six mois et son itin√©raire comportait beaucoup de petits bourgs qui n'√©taient pas desservis par les diligences . C'est √† dire qu'il voyageait en zigzag autour de la grande route . Il ne faisait pas les march√©s , mais approvisionnait les revendeurs . POUR LA M√âMOIRE FAMILIALE FAMILLE HISTOIRE SOUVENIRS & COMMENTAIRES VOLUME 1 Jean-Georges Lambert Avril 1993 J'ai entrepris ce travail pour mes fils qui tiennent √† parts √©gales , tant de place dans ma vie . Je veux l'offrir aussi √† mes belles-filles pour les remercier , chacune , d'√™tre ce qu'elles sont . VOLUME 1\n",
      "\n",
      "Page\n",
      "6- Pr√©ambule.\n",
      "\n",
      "TABLE DES MATIERES DES VOLUMES 1 & 2\n",
      "-TONE 1-MA FAMILLE PATERNELLE -\n",
      "\n",
      "11 Pr√©ambule du Tome I.\n",
      "\n",
      "18 PREMIERE PARTIE : Pour faire le point au temps de ma jeunesse\n",
      "\n",
      "19-Chapitre I: Objet de cette premi√®re partie.\n",
      "\n",
      "20-Chapitre II: Un climat passionnel.\n",
      "-Le g√©nocide nazi -L'antis√©mitisme dans le monde arabe et musulman -L'√©dition et les\n",
      "m√©dias -Cons√©quence de ce qui pr√©c√©de La r√©surgence du nazisme\n",
      "\n",
      "25-Chapitre III: Les Juifs entre les deux querre\n",
      "-Le temps de ma jeunesse -Les pr√©jug√©s entre fran√ßais -L'attitude envers les √©trangers\n",
      "-Les juifs allemands -L'antis√©mitisme en France entre les deux guerres -L'antis√©mitisme\n",
      "en France pendant la guerre de 1940-45 -A propos des raffles et arrestations de juifs\n",
      "Respecter les fran√ßais -Additif √† propos de la raffle du Vel'd'Hiv.\n",
      "\n",
      "39-Chapitre IV: Le protestantisme Le patriotisme.\n",
      "\n",
      "41 DEUXIEME PARTIE: R√©flexion sur l'histoire des juifs.\n",
      "\n",
      "42 -Chapitre V: De l'origine de la Diaspora √† l'Empire Romain.\n",
      "-Pourquoi chercher si loin -La Diaspora La population juive √† l'√©poque du Christ -Les\n",
      "juifs dans le monde gr√©co-romain -Les juifs en Palestune apr√®s la mort du Christ -Les\n",
      "juifs en Gaule et sur les bords du Rhin -La mont√©e du christianisme et la naissance de\n",
      "l'antijudaisme chr√©tien\n",
      "\n",
      "50 -Chapitre VI: De l'Empire Romain √† l'an 1000.\n",
      "-De l'arriv√©e des barbares au VII si√®cle -L'Empire Carolingien du VIII au X¬∫ si√©les\n",
      "Le judaisme et l'activit√© intellectuelle des juifs\n",
      "\n",
      "53 -Chapitre VII: Du XI au XVe si√®cles.\n",
      "-La situation des juifs au d√©but du II¬∫ mill√©naire L'√©volution de la situation - Le\n",
      "renforcement des mesures contre les juifs -Les croisades et la peste noire -L'exil -Le\n",
      "sort des juifs du royaume de France dans le contexte historique La situation des juifs\n",
      "en Alsace et en Lorraine du XI√®me au XV√®me si√®cle- Les juifs dans les pays de l'est.\n",
      "\n",
      "59 -Chapitre VIII: Du XVI√®me si√®cle √† la R√©volution.\n",
      "-La situation en France au d√©but du XVI si√®cle -Le retour des juifs en Occident -\n",
      "L'√©volution, en France, des mentalit√©s et des attitudes vis √† vis de juifs -Les\n",
      "communaut√©s juives en France Les Marranes Les contadins et les avignonais -L'histoire\n",
      "avec un grand Het la petite histoire de la famille Les juifs de Lorraine -Les juifs\n",
      "d'Alsace -Les communaut√©s de Lorraine et d'Alsace, la religion, et les rapports avec\n",
      "les populations -Les juifs de Paris Le pouvoir roval et les juifs -Quelques remarques\n",
      "sur la situation des juifs avant la R√©volution.\n",
      "\n",
      "74 -Chapitre IX\n",
      ": La R√©volution et le Directoire.\n",
      "-Ma rencontre avec cette p√©riode de l'histoire La France des communaut√©s La situation\n",
      "morale de juifs en France -L'abb√© Gr√©goire -Les Assembl√©es et les juifs Les √©tapes de\n",
      "la R√©volutions: -Les Etats G√©n√©raux et la Constituante (1789-30/9/91)\n",
      "Metadata: {'Author': 'Jean Lambert', 'Chunk_ID': 'Pour la m√©moire familiale 1-50_Chunk1', 'Doc name': 'Pour la m√©moire familiale 1-50', 'Page_number': 2.0, 'Total_Chunks': 2.0}\n",
      "--------------------------------------------------\n",
      "Content: de Maman Michel, et il est mort √† Reims le 4 mars 1893 √¢g√© de soixante quatre ans.\n",
      "\n",
      "Son influence sur la famille est de plus courte dur√©e que celle de Maman Michel, mais c'est aussi une forte personnalit√© qui a jou√© un r√¥le important dans le d√©roulement de la vie familiale.\n",
      "\n",
      "L'histoire de Jacques Dreyfus commence √† l'√©poque o√π il exer√ßait la profession de colporteur. C'est le terme qu'employait mon p√®re, mais je pense qu'il n'est pas exact, en raison de l'importance de son commerce. Je dirais plut√¥t n√©gociant en tissus, en pr√©cisant qu'il l'exer√ßait en ambulant. Il avait pour cela une voiture √† deux chevaux assez spacieuse et confortable. Il √©tait propri√©taire de l'ensemble, ce qui para√Æt assez rare dans cette profession √† cette √©poque. Il faisait des tourn√©es d'environ six mois et son itin√©raire comportait beaucoup de petits bourgs qui n'√©taient pas desservis par les diligences. C'est √† dire qu'il voyageait en zigzag autour de la grande route. Il ne faisait pas les march√©s, mais approvisionnait les revendeurs.\n",
      "Metadata: {'Author': 'John Doe', 'Chunk_ID': 'Pdf img_Chunk2', 'Doc name': 'Pdf img', 'Page_number': 118.0, 'Total_Chunks': 2.0}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test retrieval\n",
    "query = \"Who is Jean Lambert?\"\n",
    "results = retriever.get_relevant_documents(query)\n",
    "\n",
    "# Print results\n",
    "for doc in results:\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "text_field = \"text\"  # the metadata field that contains our text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from pprint import pformat\n",
    "import ast\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from typing import List, Union\n",
    "from langchain.tools import tool\n",
    "import re\n",
    "\n",
    "\n",
    "# Defining Tools\n",
    "##################################################################################\n",
    "\n",
    "def format_rag_contexts(matches: list):\n",
    "    \"\"\"Formats retrieved document matches into a readable context string.\"\"\"\n",
    "    contexts = []\n",
    "    for x in matches:\n",
    "        metadata = x.get(\"metadata\", {})  # Safely get metadata\n",
    "        text = (\n",
    "            f\"Doc name: {metadata.get('Doc name', 'N/A')}\\n\"\n",
    "            f\"Author: {metadata.get('Author', 'N/A')}\\n\"\n",
    "            f\"Chunk_ID: {metadata.get('Chunk_ID', 'N/A')}\\n\"\n",
    "            f\"Content: {metadata.get('text', 'No content available')}\"  # Fixed page content reference\n",
    "        )\n",
    "        contexts.append(text)\n",
    "\n",
    "    return \"\\n---\\n\".join(contexts)\n",
    "\n",
    "\n",
    "def translate_to_french(query: str):\n",
    "    \"\"\"Translates the given query to French using OpenAI's `o4-mini` model to improve retriebal in French database.\"\"\"\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o\",  # \"o4-mini\" may refer to \"gpt-4o\"\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a translation assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Translate the following text to French:\\n{query}\"}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "# Tool for RAG search\n",
    "def rag_search(query: str):\n",
    "    \"\"\"Finds relevant information using a natural language query and retrieves ¬±3 context chunks.\"\"\"\n",
    "    \n",
    "    results = retriever.get_relevant_documents(query, k=10)\n",
    "    if not results:\n",
    "        return \"‚ö† No relevant documents found.\"\n",
    "\n",
    "    best_match = results[0].metadata\n",
    "    doc_name = best_match.get(\"Doc name\", \"\")\n",
    "    chunk_id = best_match.get(\"Chunk_ID\", \"\")\n",
    "    total_chunks = int(best_match.get(\"Total_Chunks\", 1))\n",
    "\n",
    "    match = re.match(r\"(.+)_Chunk(\\d+)\", chunk_id)\n",
    "    if not match:\n",
    "        return results  \n",
    "\n",
    "    _, chunk_num = match.groups()\n",
    "    chunk_num = int(chunk_num)\n",
    "\n",
    "    # Generate surrounding chunk IDs (-3 to +3, within range)\n",
    "    expanded_chunk_ids = [f\"{doc_name}_Chunk{i}\" for i in range(max(1, chunk_num - 3), min(total_chunks, chunk_num + 3) + 1)]\n",
    "\n",
    "    # Retrieve only matching expanded chunks\n",
    "    expanded_results = [\n",
    "        doc for doc in retriever.get_relevant_documents(query, k=6)\n",
    "        if doc.metadata.get(\"Chunk_ID\") in expanded_chunk_ids\n",
    "    ]\n",
    "\n",
    "    # Remove duplicates based on `Chunk_ID`\n",
    "    unique_chunks = {doc.metadata[\"Chunk_ID\"]: doc.page_content for doc in expanded_results}\n",
    "\n",
    "    return \"\\n\\n\".join(unique_chunks.values()) if unique_chunks else \"‚ö† No context found.\"\n",
    "\n",
    "\n",
    "\n",
    "def final_answer(answer: str, explore_next: str = \"Would you like to ask about another topic?\", sources: str = None):\n",
    "    \"\"\"\n",
    "    Formats the final answer using a structured approach.\n",
    "\n",
    "    Args:\n",
    "        answer (str): The main response.\n",
    "        explore_next (str, optional): Suggested next question.\n",
    "        sources (str, optional): Source references.\n",
    "\n",
    "    Returns:\n",
    "        str: A well-structured response.\n",
    "    \"\"\"\n",
    "\n",
    "    # üîπ Construct sources section only if sources are available\n",
    "    sources_section = f\"- **Sources**: {sources}\" if sources and sources.lower() != 'none' else \"\"\n",
    "\n",
    "    # üîπ Define the structured prompt within the function\n",
    "    final_answer_prompt = PromptTemplate.from_template(\"\"\"\n",
    "    You are an intelligent assistant helping with historical research.\n",
    "    Format the final answer for the user by including:\n",
    "\n",
    "    - **Answer**: {answer}\n",
    "    {sources_section}\n",
    "    - **Explore Next**: {explore_next}\n",
    "\n",
    "    Ensure the response is clear and well-structured.\n",
    "    \"\"\")\n",
    "\n",
    "    # üîπ Ensure all fields are properly formatted before passing to the prompt\n",
    "    structured_input = {\n",
    "        \"answer\": answer,\n",
    "        \"explore_next\": explore_next if explore_next else \"No further suggestions.\",\n",
    "        \"sources_section\": sources_section\n",
    "    }\n",
    "\n",
    "    # üîπ Use the embedded prompt template to format the response\n",
    "    formatted_response = final_answer_prompt.format(**structured_input)\n",
    "\n",
    "    return formatted_response  # ‚úÖ Always returns a well-structured response\n",
    "\n",
    "\n",
    "\n",
    "# Binding tools to the LLM\n",
    "##################################################################################\n",
    "\n",
    "# Create tool bindings with additional attributes\n",
    "from langchain.tools import Tool\n",
    "\n",
    "# # Tool for formatting RAG contexts\n",
    "# format_rag_contexts_tool = Tool.from_function(\n",
    "#     func=format_rag_contexts,\n",
    "#     name=\"format_rag_contexts\",\n",
    "#     description=\"Formats retrieved document matches into a readable context string.\",\n",
    "#     return_direct=False\n",
    "# )\n",
    "\n",
    "# Tool for translating text to French\n",
    "translate_to_french_tool = Tool.from_function(\n",
    "    func=translate_to_french,\n",
    "    name=\"translate_to_french\",\n",
    "    description=\"Translates the given query to French using OpenAI's GPT-4o model to improve retrieval in a French database.\",\n",
    "    return_direct=False\n",
    ")\n",
    "\n",
    "# Tool for RAG search\n",
    "rag_search_tool = Tool.from_function(\n",
    "    func=rag_search,\n",
    "    name=\"rag_search\",\n",
    "    description=\"Finds related information using a natural language query in the family history database.\",\n",
    "    return_direct=False\n",
    ")\n",
    "\n",
    "# # Tool for chunk search\n",
    "# chunk_search_tool = Tool.from_function(\n",
    "#     func=chunk_search,\n",
    "#     name=\"chunk_search\",\n",
    "#     description=\"Finds related information based on the chunk_id, helping to get more context around a given chunk.\",\n",
    "#     return_direct=False\n",
    "# )\n",
    "\n",
    "# Tool for final answer generation\n",
    "final_answer_tool = Tool.from_function(\n",
    "    func=final_answer,\n",
    "    name=\"final_answer\",\n",
    "    description=(\n",
    "        \"Generates a natural language response to the user's question based on the family memory database. \"\n",
    "        \"Links information together from multiple sources but does not invent new information. \"\n",
    "        \"If no answer is found, it explicitly states that it doesn't know.\"\n",
    "    ),\n",
    "    return_direct=False\n",
    ")\n",
    "\n",
    "# List of all tools\n",
    "toolbox = [\n",
    "    translate_to_french_tool,\n",
    "    rag_search_tool,\n",
    "    final_answer_tool\n",
    "]\n",
    "\n",
    "\n",
    "# OPENAI_API_KEY environment variable must be set\n",
    "simple_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm_with_tools = simple_llm.bind_tools(toolbox)\n",
    "\n",
    "\n",
    "# Defining Agent's node\n",
    "##################################################################################\n",
    "\n",
    "# System message\n",
    "assistant_system_message = SystemMessage(content=(\"\"\"You are the Family Safe, keeper of the family's collective memory. \n",
    "Your role is to decide how to handle user queries using the available tools.\n",
    "\n",
    "**Tool Usage:**\n",
    "- Do NOT reuse a tool for the same query.\n",
    "- Do NOT use any tool more than **5 times**.\n",
    "- Prioritize **rag_search** for gathering information.\n",
    "- Do not mix sources from different contexts unless necessary.\n",
    "- Alsways check at leats 2 ***Doc name*** to ensure the information is correct.\n",
    "\n",
    "**Response Protocol:**\n",
    "- If tools provides no answer, state that you don't know or can't any information about this topic\"\n",
    "- NEVER invent information or use data beyond the family memory.\n",
    "- Always provide sources via the **final_answer** tool.\n",
    "- Chunk_search must be in the scracthpad to point to final_answer.\n",
    "- Discard any page content that looks like a table of content: you won't find any useful information there apart from page numbers.\n",
    "\n",
    "By following these rules, you ensure accurate and responsible responses.\"\"\"))\n",
    "\n",
    "# Node\n",
    "def assistant(state: MessagesState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([assistant_system_message] + state[\"messages\"])]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Defining Graph\n",
    "##################################################################################\n",
    "\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(toolbox))\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "react_graph_with_memory = builder.compile(checkpointer=memory)\n",
    "\n",
    "# Show\n",
    "display(Image(react_graph_with_memory.get_graph(xray=True).draw_mermaid_png()))\n",
    "\n",
    "# Define oracle function\n",
    "################################################################################################\n",
    "\n",
    "# Specify a thread\n",
    "def oracle(user_request: str, thread_id = \"1\", verbose = False):\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    messages = react_graph_with_memory.invoke({\"messages\": [HumanMessage(content=user_request)]}, config)\n",
    "    if verbose:\n",
    "        for message in messages['messages']:\n",
    "            message.pretty_print()\n",
    "    else:\n",
    "        messages['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "- **Answer**: Oui, il a des fr√®res et s≈ìurs. Louis et Rachel, ses parents, ont eu six enfants: Charlotte, Jacques, Alexandre, Lehmann (ou Cl√©ment), Marx, et Julie. Notre anc√™tre direct est Lehmann, n√© en 1800.\n",
      "\n",
      "- **Explore Next**: Would you like to ask about another topic?\n"
     ]
    }
   ],
   "source": [
    "oracle(\n",
    "    user_request=\"Does he have siblings?\", \n",
    "    thread_id=\"300\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "**Answer**: I couldn't find specific information regarding when Jean started to write his book. The details may not be available in the family history database.\n",
      "\n",
      "**Explore Next**: Would you like to ask about another topic?\n"
     ]
    }
   ],
   "source": [
    "oracle(\n",
    "    user_request=\"When did Jean start to write this book?\", \n",
    "    thread_id=\"5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "**Answer**: Jean's mother died on March 29, 1963.\n",
      "\n",
      "**Explore Next**: Would you like to ask about another topic?\n"
     ]
    }
   ],
   "source": [
    "oracle(\n",
    "    user_request=\"When did Jean's mother died?\", \n",
    "    thread_id=\"5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "**Answer**: I don‚Äôt know any specific information about Elon Musk.\n",
      "\n",
      "**Explore Next**: Would you like to ask about another topic?\n"
     ]
    }
   ],
   "source": [
    "oracle(\n",
    "    user_request=\"Who is Elon Musk?\", \n",
    "    thread_id=\"70\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "**Answer**: Jean a eu 6 enfants : Charlotte, Jacques, Alexandre, Lehmann (ou Cl√©ment), Marx et Julie. Ces enfants sont n√©s √† Froeningen entre 1795 et 1802.\n",
      "\n",
      "**Explore Next**: Would you like to ask about another topic?\n"
     ]
    }
   ],
   "source": [
    "oracle(\n",
    "    user_request=\"Combien d'enfant a Jean?\", \n",
    "    thread_id=\"9\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "### Answer:\n",
      "In the documents related to 'sons' from chunks 7 and 8, there is no specific mention or detailed information about any sons. The content primarily revolves around the author's reflections on their upbringing, family history, and their mother's death. Unfortunately, this content does not contain pertinent information about sons within these specific chunks.\n",
      "\n",
      "### Explore Next:\n",
      "Would you like to ask about another topic?\n"
     ]
    }
   ],
   "source": [
    "oracle(\n",
    "    user_request=\"Can you check for sons in chunk 7 & 8?\", \n",
    "    thread_id=\"7\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "- **Answer**: Jean's sentiments appear to involve a nuanced view of Jewish communities, acknowledging challenges and advocating for their rights and recognition. He highlights the moral responsibility of society to improve their situation, suggesting that Judaism should not be seen in a negative light and emphasizes the importance of respect and recognition of individuals in the community.\n",
      "\n",
      "- **Explore Next**: Would you like to ask about another topic?\n"
     ]
    }
   ],
   "source": [
    "oracle(\n",
    "    user_request=\"What does Jean has to say about it?\", \n",
    "    thread_id=\"8\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "**Answer**: The personal anecdotes reflect a rich tapestry of family history, emphasizing the dramatic changes in cultural values and traditions over generations. The narrator shares insights from their father's notes, revealing a serene perspective on Jewish identity and societal norms from the past, contrasting sharply with contemporary views. They discuss the significance of life events, such as birth and death, and how societal attitudes have evolved, particularly regarding mourning practices and the impact of war. These reflections serve as a bridge between generations, illustrating the profound influence of historical context on personal experiences and family legacies.\n",
      "\n",
      "**Explore Next**: Would you like to ask about another topic?\n"
     ]
    }
   ],
   "source": [
    "oracle(\n",
    "    user_request=\"Expand on his personal anecdotes\", \n",
    "    thread_id=\"5052\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurel\\AppData\\Roaming\\Python\\Python312\\site-packages\\gradio\\components\\chatbot.py:282: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# Initialize conversation history\n",
    "chat_history = []\n",
    "\n",
    "def query_oracle(user_request: str):\n",
    "    \"\"\"Invokes the LangGraph Oracle and returns a structured response.\"\"\"\n",
    "    global chat_history\n",
    "\n",
    "    try:\n",
    "        # Invoke Oracle using LangGraph with memory\n",
    "        config = {\"configurable\": {\"thread_id\": \"29\"}}\n",
    "        response = react_graph_with_memory.invoke({\"messages\": [HumanMessage(content=user_request)]}, config)\n",
    "\n",
    "        # Extract latest message (handle None case)\n",
    "        response_text = response[\"messages\"][-1].content if response and \"messages\" in response else \"‚ö† No valid response.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        response_text = f\"üö® Error: {str(e)}\"\n",
    "\n",
    "    # Store user input and Oracle response as tuple\n",
    "    chat_history.append((user_request, response_text))\n",
    "    return chat_history  # Return updated chat history for Gradio Chatbot\n",
    "\n",
    "# Function to clear chat history\n",
    "def clear_chat():\n",
    "    global chat_history\n",
    "    chat_history = []  # Reset chat history\n",
    "    return chat_history  # Reset chatbot UI\n",
    "\n",
    "# Set up Gradio Interface\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# üîÆ LangGraph Oracle Assistant\")\n",
    "    gr.Markdown(\"Ask any question about your family history, and the Oracle will respond.\")\n",
    "\n",
    "    chatbot = gr.Chatbot(label=\"Chat History\")  # Chat interface\n",
    "\n",
    "    with gr.Row():\n",
    "        user_input = gr.Textbox(label=\"Your Question\", placeholder=\"Type your question here...\", lines=1)\n",
    "        submit_button = gr.Button(\"Submit\")\n",
    "\n",
    "    # Clear Chat Button\n",
    "    clear_button = gr.Button(\"Clear Chat\")\n",
    "\n",
    "    # Connect Buttons to Functions\n",
    "    submit_button.click(query_oracle, inputs=[user_input], outputs=[chatbot])\n",
    "    clear_button.click(clear_chat, inputs=None, outputs=[chatbot])  # Clears the chat\n",
    "\n",
    "# Launch Gradio App\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç [DEBUG] Query received: Hello! How can you help me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! I can assist you with queries related to family history, collective memories, and other related topics. If you have any specific questions or topics you'd like to know more about, feel free to ask!\n",
      "üì° [DEBUG] Raw Oracle response: None\n",
      "üîç [DEBUG] Type of response: <class 'NoneType'>\n",
      "‚ö† [DEBUG] Oracle returned None. Possible failure in agent processing.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'‚ö† No response received from Oracle. Please try again.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def query_oracle(text: str):\n",
    "    \"\"\"Invokes the LangGraph agent and extracts a cleaned response.\"\"\"\n",
    "    print(f\"üîç [DEBUG] Query received: {text}\")\n",
    "\n",
    "    response = oracle(user_request=text, thread_id=\"500\")\n",
    "\n",
    "    print(f\"üì° [DEBUG] Raw Oracle response: {response}\")\n",
    "    print(f\"üîç [DEBUG] Type of response: {type(response)}\")\n",
    "\n",
    "    if response is None:\n",
    "        print(\"‚ö† [DEBUG] Oracle returned None. Possible failure in agent processing.\")\n",
    "        return \"‚ö† No response received from Oracle. Please try again.\"\n",
    "\n",
    "    return response\n",
    "\n",
    "query_oracle(\"Hello! How can you help me?\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
